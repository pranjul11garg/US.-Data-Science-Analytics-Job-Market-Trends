[
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Group 11 Skill",
    "section": "",
    "text": "import pandas as pd\ndf= pd.read_csv(\"data/lightcast_job_postings.csv\")\ndf.head()\n\n/var/folders/ml/69jz_hln1nv6px47r10h6ccm0000gn/T/ipykernel_61572/4103762630.py:2: DtypeWarning: Columns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n  df= pd.read_csv(\"data/lightcast_job_postings.csv\")\n\n\n\n\n\n\n\n\n\nID\nLAST_UPDATED_DATE\nLAST_UPDATED_TIMESTAMP\nDUPLICATES\nPOSTED\nEXPIRED\nDURATION\nSOURCE_TYPES\nSOURCES\nURL\n...\nNAICS_2022_2\nNAICS_2022_2_NAME\nNAICS_2022_3\nNAICS_2022_3_NAME\nNAICS_2022_4\nNAICS_2022_4_NAME\nNAICS_2022_5\nNAICS_2022_5_NAME\nNAICS_2022_6\nNAICS_2022_6_NAME\n\n\n\n\n0\n1f57d95acf4dc67ed2819eb12f049f6a5c11782c\n9/6/2024\n2024-09-06 20:32:57.352 Z\n0.0\n6/2/2024\n6/8/2024\n6.0\n[\\n \"Company\"\\n]\n[\\n \"brassring.com\"\\n]\n[\\n \"https://sjobs.brassring.com/TGnewUI/Sear...\n...\n44.0\nRetail Trade\n441.0\nMotor Vehicle and Parts Dealers\n4413.0\nAutomotive Parts, Accessories, and Tire Retailers\n44133.0\nAutomotive Parts and Accessories Retailers\n441330.0\nAutomotive Parts and Accessories Retailers\n\n\n1\n0cb072af26757b6c4ea9464472a50a443af681ac\n8/2/2024\n2024-08-02 17:08:58.838 Z\n0.0\n6/2/2024\n8/1/2024\nNaN\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\n[\\n \"https://joblink.maine.gov/jobs/1085740\"\\n]\n...\n56.0\nAdministrative and Support and Waste Managemen...\n561.0\nAdministrative and Support Services\n5613.0\nEmployment Services\n56132.0\nTemporary Help Services\n561320.0\nTemporary Help Services\n\n\n2\n85318b12b3331fa490d32ad014379df01855c557\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/7/2024\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\n[\\n \"https://dejobs.org/dallas-tx/data-analys...\n...\n52.0\nFinance and Insurance\n524.0\nInsurance Carriers and Related Activities\n5242.0\nAgencies, Brokerages, and Other Insurance Rela...\n52429.0\nOther Insurance Related Activities\n524291.0\nClaims Adjusting\n\n\n3\n1b5c3941e54a1889ef4f8ae55b401a550708a310\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/20/2024\n48.0\n[\\n \"Job Board\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\n[\\n \"https://www.disabledperson.com/jobs/5948...\n...\n52.0\nFinance and Insurance\n522.0\nCredit Intermediation and Related Activities\n5221.0\nDepository Credit Intermediation\n52211.0\nCommercial Banking\n522110.0\nCommercial Banking\n\n\n4\ncb5ca25f02bdf25c13edfede7931508bfd9e858f\n6/19/2024\n2024-06-19 07:00:00.000 Z\n0.0\n6/2/2024\n6/17/2024\n15.0\n[\\n \"FreeJobBoard\"\\n]\n[\\n \"craigslist.org\"\\n]\n[\\n \"https://modesto.craigslist.org/sls/77475...\n...\n99.0\nUnclassified Industry\n999.0\nUnclassified Industry\n9999.0\nUnclassified Industry\n99999.0\nUnclassified Industry\n999999.0\nUnclassified Industry\n\n\n\n\n5 rows × 131 columns\nprint(df.columns.tolist())\n#df['BODY'].head()\ndf['SKILLS_NAME'].head()\n\n\n\n['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n0    [\\n  \"Merchandising\",\\n  \"Mathematics\",\\n  \"Pr...\n1    [\\n  \"Procurement\",\\n  \"Financial Statements\",...\n2    [\\n  \"Management\",\\n  \"Exception Reporting\",\\n...\n3    [\\n  \"Exit Strategies\",\\n  \"Reliability\",\\n  \"...\n4                                                   []\nName: SKILLS_NAME, dtype: object\nimport pandas as pd\n\nskills_data = {\n    \"Name\": [\"Binderiya\", \"Pranjul\", \"Pratham\", \"Panyang\"],\n    \"Python\": [4, 4, 5, 3],\n    \"SQL\": [4, 4, 5, 4],\n    \"Machine Learning\": [2, 3, 2, 2],\n    \"PySpark\": [3, 3, 3, 3],\n    \"Excel\": [4, 5, 5, 4],\n    \"Data Visualization\": [5, 5, 3, 3],\n    \"Power Bi/ Tableau\": [4, 5, 3, 4],\n    \"Version Control Git\": [4, 4, 3, 3],\n    \"ETL/Data pipeline\": [3, 2, 1, 2],\n    \"Communication\": [4, 4, 5, 3],\n    \"Project Management\": [5, 5, 5, 3],\n    \"Cloud Computing\": [4, 4, 2, 2]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nPySpark\nExcel\nData Visualization\nPower Bi/ Tableau\nVersion Control Git\nETL/Data pipeline\nCommunication\nProject Management\nCloud Computing\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinderiya\n4\n4\n2\n3\n4\n5\n4\n4\n3\n4\n5\n4\n\n\nPranjul\n4\n4\n3\n3\n5\n5\n5\n4\n2\n4\n5\n4\n\n\nPratham\n5\n5\n2\n3\n5\n3\n3\n3\n1\n5\n5\n2\n\n\nPanyang\n3\n4\n2\n3\n4\n3\n4\n3\n2\n3\n3\n2\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(df_skills, annot=True, cmap=\"coolwarm\", linewidths=0.5)\nplt.title(\"Team Skill Levels Heatmap\")\nplt.show()\nimport plotly.graph_objects as go\nfig = go.Figure()\n\nfor name in df_skills.index:\n    values = df_skills.loc[name].tolist()\n    values += values[:1]  # close the loop\n    fig.add_trace(go.Scatterpolar(\n        r=values,\n        theta=df_skills.columns.tolist() + [df_skills.columns[0]],\n        fill='toself',\n        name=name\n    ))\n\nfig.update_layout(\n    polar=dict(radialaxis=dict(visible=True, range=[0, 5])),\n    showlegend=True,\n    title='Team Skills Radar Chart'\n)\nfig.write_html(\"figures/skills_radar_chart.html\")\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\nFrom this radar chart visualization we can see that our team has a lot of room for improvement for skills like PySpark and Machine Learning. Also we can see that not a lot of our team mates are confident in their skills in Cloud Computing and ETL."
  },
  {
    "objectID": "skill_gap_analysis.html#top-skills",
    "href": "skill_gap_analysis.html#top-skills",
    "title": "Group 11 Skill",
    "section": "Top Skills",
    "text": "Top Skills\n\nkeywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n            'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n            'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n            'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n\nmatch = lambda col: df[col].str.contains('|'.join(keywords), case=False, na=False)\n\ndf['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n             | match('SKILLS_NAME') \\\n             | match('SPECIALIZED_SKILLS_NAME') \ndf['DATA_ANALYST_JOB'].value_counts()\n\nDATA_ANALYST_JOB\nFalse    38686\nTrue     33812\nName: count, dtype: int64\n\n\n\nimport ast\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n# Safely apply literal_eval only to non-null values\ndf['SKILLS'] = df['SKILLS_NAME'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n\n\ndata_skills = df[df['DATA_ANALYST_JOB']]['SKILLS'].explode().value_counts().reset_index()\ndata_skills.columns = ['Skill', 'Count']\n\nfig = px.bar(data_skills, x='Skill', y='Count',\n             title=\"Top Skills\",\n             labels={'Skill': 'Skill Name', 'Count': 'Frequency'},\n             color='Skill')\ndf_skills.index = df_skills.index.str.strip()\n\n#fig.show()\n#fig.write_html(\"figures/5_chart.html\")\n\n\nteam_skills = [s.strip().lower() for s in df_skills.columns]\nprint(\"Team skills:\", team_skills)\nprint(job_demand_raw['Skill'].head(10).tolist())\nfor skill_text in job_demand_raw['Skill'].head(10):\n    for team_skill in team_skills:\n        if team_skill in skill_text:\n            print(f\"✅ '{team_skill}' found in: '{skill_text}'\")\n\n\nTeam skills: ['python', 'sql', 'machine learning', 'pyspark', 'excel', 'data visualization', 'power bi/ tableau', 'version control git', 'etl/data pipeline', 'communication', 'project management', 'cloud computing']\n['data analysis', 'sql (programming language)', 'communication', 'management', 'python (programming language)', 'tableau (business intelligence software)', 'dashboard', 'computer science', 'problem solving', 'power bi']\n✅ 'sql' found in: 'sql (programming language)'\n✅ 'communication' found in: 'communication'\n✅ 'python' found in: 'python (programming language)'\n\n\n\nfor _, row in job_demand_raw.iterrows():\n    skill_text = row['Skill']\n    count = row['Count']\n    for team_skill in team_skills:\n        if team_skill in skill_text:  # no regex, just substring\n            skill_demand_map[team_skill] += count\n\njob_demand = pd.Series(skill_demand_map)\nprint(job_demand)\n\nsql                   74649\ncommunication         75138\npython                34554\nexcel                 29586\ndata visualization    22761\nproject management    23184\nmachine learning      13002\ncloud computing        4041\npyspark                1539\ndtype: int64\n\n\n\njob_demand = pd.Series(skill_demand_map)\njob_demand.name = \"Count\"\nteam_avg = df_skills.mean()\nteam_avg.index = team_avg.index.str.strip().str.lower() \n# Now match only overlapping skills\ncommon_skills = job_demand.index.intersection(team_avg.index)\nteam_avg = team_avg[common_skills]\njob_demand = job_demand[common_skills]\n\n# Normalize job demand\njob_demand_normalized = 5 * (job_demand / job_demand.max())\njob_demand_normalized.name = \"Job Demand (Normalized)\"\n\n# Combine\ncomparison_df = pd.concat([team_avg, job_demand_normalized], axis=1)\ncomparison_df.columns = [\"Team Average Skill\", \"Job Demand (Normalized)\"]\ncomparison_df[\"Skill Gap\"] = comparison_df[\"Job Demand (Normalized)\"] - comparison_df[\"Team Average Skill\"]\ncomparison_df.sort_values(\"Skill Gap\", ascending=False, inplace=True)\n\ncomparison_df\n\n\n\n\n\n\n\n\nTeam Average Skill\nJob Demand (Normalized)\nSkill Gap\n\n\n\n\ncommunication\n4.00\n5.000000\n1.000000\n\n\nsql\n4.25\n4.967460\n0.717460\n\n\nmachine learning\n2.25\n0.865208\n-1.384792\n\n\npython\n4.00\n2.299369\n-1.700631\n\n\ndata visualization\n4.00\n1.514613\n-2.485387\n\n\nexcel\n4.50\n1.968777\n-2.531223\n\n\ncloud computing\n3.00\n0.268905\n-2.731095\n\n\npyspark\n3.00\n0.102412\n-2.897588\n\n\nproject management\n4.50\n1.542761\n-2.957239\n\n\n\n\n\n\n\n\ncomparison_df[\"Skill Gap\"].plot(kind='bar', color='crimson', figsize=(10, 5), title='Skill Gaps: Market vs Team')\nplt.axhline(0, color='black', linestyle='--')\nplt.ylabel('Gap (Demand - Team Skill)')\nplt.grid(axis='y')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ncomparison_df = comparison_df.reset_index().rename(columns={\"index\": \"Skill\"})\n\n\nimport plotly.express as px\n\nfig = px.bar(\n    comparison_df,\n    x='Skill',\n    y='Skill Gap',\n    color='Skill Gap',\n    color_continuous_scale='RdBu_r',\n    title='Skill Gaps: Job Market Expectations vs. Team Capability',\n    labels={'Skill Gap': 'Gap (Job Demand - Team Skill)', 'Skill': 'Skill'},\n)\n\nfig.add_hline(y=0, line_dash='dash')\nfig.update_layout(\n    xaxis_tickangle=-45,\n    yaxis_title='Gap (Positive = Market expects more)',\n    font=dict(size=13),\n    height=500,\n    plot_bgcolor='white',\n)\nfig.write_html(\"figures/skill_gap_chart.html\")\n\n\nfig.show()\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nThis bar chart compares our team’s average proficiency in key data-related skills against job market expectations. Skills with positive values (like communication and SQL) indicate areas where market demand exceeds our current capabilities. On the other hand, negative values highlight areas where the team is ahead or closely aligned with market needs. Notably, skills like Python, cloud computing, and project management show the largest gaps, suggesting priority areas for upskilling."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Trends in Data Science & Business Analytics!",
    "section": "",
    "text": "Welcome to our deep dive into the evolving landscape of Data Science and Business Analytics in the United States. As industries across the nation increasingly rely on data-driven insights, the role of data science and analytics has become paramount in shaping business strategies, optimizing operations, and driving innovation.\nThe rise of artificial intelligence (AI) is reshaping the landscape of data science and business analytics in the United States, creating both opportunities and challenges for workers and businesses alike. As AI continues to evolve, it has sparked widespread concern over job displacement. According to a recent report from the World Economic Forum, 86% of workers express concerns about AI potentially leading to job losses, with predictions of significant industry shifts occurring within the next two to five years (Samuels (2024)). However, business leaders emphasize that AI is not merely a tool for job replacement—it’s a transformative force that is changing the nature of work itself. For instance, Rakuten’s partnership with OpenAI to create an internal version of ChatGPT is helping employees work more efficiently, focusing on higher-level tasks rather than being displaced by technology (Samuels (2024)).\n\n\n\nData Science Image\n\n\nOne key trend in 2024 is the growing demand for AI-related skills across various industries. A recent Gartner report highlights that many organizations are significantly increasing their investments in AI, with companies projected to spend an average of $2.5 million on AI integration in 2024 (Gartner (2024)). This investment is reshaping job descriptions and workforce requirements, as roles now demand proficiency in AI tools. For example, in software development, GitHub Copilot has been shown to increase programmers’ efficiency by 55%, enabling them to focus on complex problem-solving rather than repetitive coding tasks (GitHub (2023)). As a result, professionals who upskill and learn to work alongside AI will have better career prospects in the future.\n\n\n\nData Science Image\n\n\nThe career outlook for business analytics and data science professionals remains optimistic, as companies increasingly look to combine AI with human decision-making to enhance productivity and innovation. Industry leaders, including Bev White, CEO of Nash Squared, emphasize that AI is not about eliminating jobs, but rather reshaping them to make work more productive and meaningful (White (2024)). Similarly, PepsiCo’s CIO, Nigel Richardson, believes that while some jobs will be replaced, AI will ultimately create more opportunities than it eliminates (Richardson (2024)). This aligns with a McKinsey report that forecasts AI could generate up to $13 trillion in additional global GDP by 2030, creating new job opportunities in data science, business analytics, and other technology-related fields (Company (2023)).\nThis website explores the latest trends, key developments, and future directions in Data Science and Business Analytics in the U.S. We delve into emerging technologies, the growing demand for skilled professionals, and the impact these fields are having on various industries. Our aim is to provide you with valuable insights into how data science is shaping the future of business and the economy.\nJoin us as we explore:\n\nThe role of machine learning, AI, and automation in business analytics.\nHow data-driven decisions are driving competitive advantages across industries.\nThe growing importance of data ethics and privacy concerns.\nKey skills and tools shaping the future of data professionals.\n\n\n\n\n\nReferences\n\nCompany, M. &. (2023): “The Economic Potential of Generative AI: The Next Productivity Frontier,”https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier.\n\n\nGartner. (2024): “Marketing Budgets: Benchmarks for CMOs in the Era of Less,”https://www.gartner.com/en/marketing/topics/marketing-budget.\n\n\nGitHub. (2023): “GitHub Copilot: Your AI Pair Programmer,”https://github.com/features/copilot.\n\n\nRichardson, N. (2024): “CIO Interview: Nigel Richardson, European CIO, PepsiCo,”https://www.computerweekly.com/news/366570412/CIO-interview-Nigel-Richardson-European-CIO-PepsiCo.\n\n\nSamuels, M. (2024): “AI’s Employment Impact: 86% of Workers Fear Job Losses, but Here’s Some Good News,”https://www.zdnet.com/article/ai-employment-impact-86-of-workers-fear-job-losses-but-heres-some-good-news/.\n\n\nWhite, B. (2024): “The Future of Work: How AI Is Reshaping Careers,”https://www.harveynash.co.uk/team/bev-white."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "EDA",
    "section": "",
    "text": "import pandas as pd\neda = pd.read_csv('./data/eda_data.csv')\neda.head()\n\n\n\n\n\n\n\n\nCOMPANY\nLOCATION\nPOSTED\nMIN_EDULEVELS_NAME\nMAX_EDULEVELS_NAME\nMIN_YEARS_EXPERIENCE\nMAX_YEARS_EXPERIENCE\nTITLE\nSKILLS\nSPECIALIZED_SKILLS\n...\nCOMMON_SKILLS\nSOFTWARE_SKILLS\nSOC_2021_4_NAME\nNAICS_2022_6\nNAICS2_NAME\nREMOTE_TYPE_NAME\nSALARY\nTITLE_NAME\nSKILLS_NAME\nSPECIALIZED_SKILLS_NAME\n\n\n\n\n0\n894731\n{\\n \"lat\": 33.20763,\\n \"lon\": -92.6662674\\n}\n2024-06-02\nBachelor's degree\nMaster's degree\n2.000000\n2.000000\nET29C073C03D1F86B4\n[\\n \"KS126DB6T061MHD7RTGQ\",\\n \"KS126706DPFD3...\n[\\n \"KS126DB6T061MHD7RTGQ\",\\n \"KS128006L3V0H...\n...\n[\\n \"KS126706DPFD3354M7YK\",\\n \"KS1280B68GD79...\n[\\n \"KS440W865GC4VRBW6LJP\",\\n \"KS13USA80NE38...\nData Scientists\n441330\nRetail Trade\n[None]\n116348.5\nEnterprise Analysts\n[\\n \"Merchandising\",\\n \"Mathematics\",\\n \"Pr...\n[\\n \"Merchandising\",\\n \"Predictive Modeling\"...\n\n\n1\n133098\n{\\n \"lat\": 44.3106241,\\n \"lon\": -69.7794897\\n}\n2024-06-02\nNo Education Listed\nMaster's degree\n3.000000\n3.000000\nET21DDA63780A7DC09\n[\\n \"KS122626T550SLQ7QZ1C\",\\n \"KS123YJ6KVWC9...\n[\\n \"KS122626T550SLQ7QZ1C\",\\n \"KS123YJ6KVWC9...\n...\n[]\n[\\n \"BGSBF3F508F7F46312E3\",\\n \"ESEA839CED378...\nData Scientists\n561320\nAdministrative and Support and Waste Managemen...\nRemote\n116348.5\nOracle Consultants\n[\\n \"Procurement\",\\n \"Financial Statements\",...\n[\\n \"Procurement\",\\n \"Financial Statements\",...\n\n\n2\n39063746\n{\\n \"lat\": 32.7766642,\\n \"lon\": -96.7969879\\n}\n2024-06-02\nBachelor's degree\nMaster's degree\n5.000000\n3.773903\nET3037E0C947A02404\n[\\n \"KS1218W78FGVPVP2KXPX\",\\n \"ESF3939CE1F80...\n[\\n \"ESF3939CE1F80C10C327\",\\n \"KS120GV6C72JM...\n...\n[\\n \"KS1218W78FGVPVP2KXPX\",\\n \"BGS1ADAA36DB6...\n[\\n \"KS126HY6YLTB9R7XJC4Z\"\\n]\nData Scientists\n524291\nFinance and Insurance\n[None]\n116348.5\nData Analysts\n[\\n \"Management\",\\n \"Exception Reporting\",\\n...\n[\\n \"Exception Reporting\",\\n \"Data Analysis\"...\n\n\n3\n37615159\n{\\n \"lat\": 33.4483771,\\n \"lon\": -112.0740373\\n}\n2024-06-02\nNo Education Listed\nMaster's degree\n3.000000\n3.773903\nET2114E0404BA30075\n[\\n \"KS123QX62QYTC4JF38H8\",\\n \"KS7G6NP6R6L1H...\n[\\n \"KS123QX62QYTC4JF38H8\",\\n \"KS441PQ64HT13...\n...\n[\\n \"KS7G6NP6R6L1H1SKFTSY\",\\n \"KS1218W78FGVP...\n[\\n \"KS4409D76NW1S5LNCL18\",\\n \"ESC7869CF7378...\nData Scientists\n522110\nFinance and Insurance\n[None]\n116348.5\nManagement Analysts\n[\\n \"Exit Strategies\",\\n \"Reliability\",\\n \"...\n[\\n \"Exit Strategies\",\\n \"User Story\",\\n \"H...\n\n\n4\n0\n{\\n \"lat\": 37.6392595,\\n \"lon\": -120.9970014\\n}\n2024-06-02\nNo Education Listed\nMaster's degree\n5.486539\n3.773903\nET0000000000000000\n[]\n[]\n...\n[]\n[]\nData Scientists\n999999\nUnclassified Industry\n[None]\n92500.0\nUnclassified\n[]\n[]\n\n\n\n\n5 rows × 21 columns\n\n\n\n\n# identifying data analyst jobs by keyword searching\nkeywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n            'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n            'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n            'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n\nmatch = lambda col: eda[col].str.contains('|'.join(keywords), case=False, na=False)\n\neda['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n             | match('SKILLS_NAME') \\\n             | match('SPECIALIZED_SKILLS_NAME') \neda['DATA_ANALYST_JOB'].value_counts()\n\nDATA_ANALYST_JOB\nFalse    37052\nTrue     32148\nName: count, dtype: int64\n\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Group data (same as before)\ndf_grouped = eda.groupby(['DATA_ANALYST_JOB', 'NAICS2_NAME']).size().reset_index(name='Job_Count')\n\n# Shorten the industry names (NAICS2_NAME) for better readability\n# Assuming NAICS2_NAME has long names, we'll map them to shorter versions\n# Example: Replace long names with abbreviations or shorter terms\nindustry_short_names = {\n    'Professional, Scientific, and Technical Services': 'Prof. Services',\n    'Administrative and Support and Waste Management and Remediation Services': 'Admin & Waste Mgmt',\n    'Health Care and Social Assistance': 'Healthcare',\n    'Finance and Insurance': 'Finance',\n    'Information': 'Info Tech',\n    'Educational Services': 'Education',\n    'Manufacturing': 'Manufacturing',\n    'Retail Trade': 'Retail',\n    'Accommodation and Food Services': 'Hospitality',\n    'Other Services (except Public Administration)': 'Other Services',\n    # Add more mappings as needed based on your dataset\n}\n\n# Apply the shortened names to the dataframe\ndf_grouped['NAICS2_NAME_SHORT'] = df_grouped['NAICS2_NAME'].map(industry_short_names).fillna(df_grouped['NAICS2_NAME'])\n\n# Define a vibrant and modern color palette\ncolor_map = {\n    False: \"#FF6B6B\",  # Coral red for False\n    True: \"#4ECDC4\"    # Teal for True\n}\n\n# Create the bar plot with Plotly Express\nfig = px.bar(df_grouped, \n             x='NAICS2_NAME_SHORT',  # Use shortened names\n             y='Job_Count',\n             color='DATA_ANALYST_JOB',\n             title=\"Data & Business Analytics Job Trends\",\n             labels={'NAICS2_NAME_SHORT': 'Industry', 'Job_Count': 'Number of Jobs'},\n             barmode='group',\n             color_discrete_map=color_map\n            )\n\n# Beautify the layout with a modern, clean design\nfig.update_layout(\n    # Sizing and margins\n    autosize=True,\n    width=1100,  # Slightly narrower for better focus\n    height=650,  # Adjusted height\n    margin=dict(l=50, r=50, t=90, b=120),  # Adjusted margins for cleaner look\n\n    # Background and plot styling\n    plot_bgcolor='rgba(240, 240, 245, 1)',  # Softer gray background\n    paper_bgcolor='rgba(255, 255, 255, 1)',  # White paper background\n    font=dict(family=\"Helvetica, sans-serif\", size=14, color=\"#2D3748\"),  # Modern font\n\n    # Title styling\n    title=dict(\n        text=\"Data & Business Analytics Job Trends\",\n        font=dict(size=26, color=\"#2D3748\", family=\"Helvetica, sans-serif\"),\n        x=0.5,  # Center the title\n        xanchor=\"center\",\n        y=0.95,\n        yanchor=\"top\"\n    ),\n\n    # X-axis styling\n    xaxis=dict(\n        title=\"Industry\",\n        title_font=dict(size=18, color=\"#2D3748\"),\n        tickfont=dict(size=13, color=\"#4A5568\"),\n        tickangle=-30,  # Slightly less aggressive rotation\n        gridcolor=\"rgba(200, 200, 200, 0.2)\",  # Very light gridlines\n        linecolor=\"#2D3748\",\n        linewidth=2,\n        showline=True\n    ),\n\n    # Y-axis styling\n    yaxis=dict(\n        title=\"Number of Jobs\",\n        title_font=dict(size=18, color=\"#2D3748\"),\n        tickfont=dict(size=13, color=\"#4A5568\"),\n        range=[0, df_grouped['Job_Count'].max() * 1.15],  # Slightly tighter range\n        gridcolor=\"rgba(200, 200, 200, 0.2)\",\n        linecolor=\"#2D3748\",\n        linewidth=2,\n        showline=True\n    ),\n\n    # Legend styling\n    legend=dict(\n        title=\"Job Type\",\n        font=dict(size=13, color=\"#2D3748\"),\n        bgcolor=\"rgba(255, 255, 255, 0.95)\",\n        bordercolor=\"#2D3748\",\n        borderwidth=1,\n        x=1.02,  # Position outside\n        y=0.5,\n        xanchor=\"left\",\n        yanchor=\"middle\"\n    ),\n\n    # Hover and interactivity\n    hovermode=\"closest\",\n    hoverlabel=dict(\n        bgcolor=\"rgba(255, 255, 255, 0.9)\",\n        font_size=13,\n        font_family=\"Helvetica, sans-serif\",\n        font_color=\"#2D3748\",\n        bordercolor=\"#2D3748\"\n    ),\n\n    # Add a subtle shadow effect for depth\n    bargap=0.2,  # Add space between bars for clarity\n)\n\n# Customize the bars\nfig.update_traces(\n    marker=dict(\n        line=dict(width=1.2, color=\"#2D3748\"),  # Thinner border for elegance\n        # Add a gradient effect to the bars\n        coloraxis=None,\n    ),\n    opacity=0.85,  # Slight transparency for softness\n    text=df_grouped['Job_Count'],  # Add labels on bars\n    textposition='outside',  # Place labels outside for clarity\n    textfont=dict(size=12, color=\"#2D3748\", family=\"Helvetica, sans-serif\"),\n    texttemplate='%{text}',  # Show just the number\n)\n\n# Add a subtle annotation for the highest job count\nmax_job = df_grouped.loc[df_grouped['Job_Count'].idxmax()]\nfig.add_annotation(\n    x=max_job['NAICS2_NAME_SHORT'],\n    y=max_job['Job_Count'] * 1.1,\n    text=f\"Top: {max_job['NAICS2_NAME_SHORT']}&lt;br&gt;{max_job['Job_Count']} Jobs\",\n    showarrow=True,\n    arrowhead=1,\n    ax=20,\n    ay=-40,\n    font=dict(size=13, color=\"#2D3748\", family=\"Helvetica, sans-serif\"),\n    bgcolor=\"rgba(255, 255, 255, 0.85)\",\n    bordercolor=\"#2D3748\",\n    borderwidth=1,\n    borderpad=4\n)\n\n                                                \n\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Identify the top 10 industries with the most data analyst jobs\ntop_industries = df_grouped.groupby(\"NAICS2_NAME\")[\"Job_Count\"].sum().nlargest(10).index\n\n# Filter the dataset for top industries\ndf_top_industries = df_grouped[df_grouped[\"NAICS2_NAME\"].isin(top_industries)].copy()\n\n# Shorten industry names for better readability\nindustry_short_names = {\n    'Professional, Scientific, and Technical Services': 'Prof. Services',\n    'Administrative and Support and Waste Management and Remediation Services': 'Admin & Waste Mgmt',\n    'Health Care and Social Assistance': 'Healthcare',\n    'Finance and Insurance': 'Finance',\n    'Information': 'Info Tech',\n    'Educational Services': 'Education',\n    'Manufacturing': 'Manufacturing',\n    'Retail Trade': 'Retail',\n    'Accommodation and Food Services': 'Hospitality',\n    'Other Services (except Public Administration)': 'Other Services',\n}\ndf_top_industries['NAICS2_NAME_SHORT'] = df_top_industries['NAICS2_NAME'].map(industry_short_names).fillna(df_top_industries['NAICS2_NAME'])\n\n# Update DATA_ANALYST_JOB labels for clarity\ndf_top_industries['Job_Category'] = df_top_industries['DATA_ANALYST_JOB'].map({True: 'Data Analyst', False: 'Business Analyst'})\n\n# Define a modern, vibrant color palette for industries (10 colors for top 10 industries)\ncolor_palette = [\n    '#FF6B6B',  # Coral Red\n    '#4ECDC4',  # Teal\n    '#45B7D1',  # Sky Blue\n    '#96CEB4',  # Sage Green\n    '#FFEEAD',  # Soft Yellow\n    '#D4A5A5',  # Dusty Rose\n    '#9B59B6',  # Purple\n    '#3498DB',  # Bright Blue\n    '#E67E22',  # Orange\n    '#1ABC9C',  # Turquoise\n]\ncolor_map = {industry: color for industry, color in zip(df_top_industries['NAICS2_NAME_SHORT'].unique(), color_palette)}\n\n# Create the bar chart\nfig = px.bar(df_top_industries, \n             x=\"Job_Category\",  # Use the updated labels\n             y=\"Job_Count\", \n             color=\"NAICS2_NAME_SHORT\",\n             title=\"Top 10 Industries Hiring Data & Business Analysts\",\n             labels={'Job_Category': 'Job Category', 'Job_Count': 'Number of Jobs', 'NAICS2_NAME_SHORT': 'Industry'},\n             barmode='group')\n\n# Beautify the layout\nfig.update_layout(\n    # Sizing and margins\n    autosize=True,\n    width=1150,  # Slightly wider for balance\n    height=650,  # Adjusted height\n    margin=dict(l=60, r=150, t=100, b=80),  # Adjusted for legend and title\n\n    # Background and plot styling\n    plot_bgcolor='rgba(245, 245, 250, 1)',  # Very light lavender-gray\n    paper_bgcolor='rgba(255, 255, 255, 1)',  # White paper background\n    font=dict(family=\"Poppins, sans-serif\", size=14, color=\"#2D3436\"),  # Modern, elegant font\n\n    # Title styling\n    title=dict(\n        text=\"Top 10 Industries Hiring Data & Business Analysts\",\n        font=dict(size=28, color=\"#2D3436\", family=\"Poppins, sans-serif\"),\n        x=0.5,\n        xanchor=\"center\",\n        y=0.95,\n        yanchor=\"top\"\n    ),\n\n    # X-axis styling\n    xaxis=dict(\n        title=\"Job Category\",\n        title_font=dict(size=18, color=\"#2D3436\"),\n        tickfont=dict(size=14, color=\"#636E72\"),\n        gridcolor=\"rgba(200, 200, 200, 0.1)\",  # Very subtle gridlines\n        linecolor=\"#2D3436\",\n        linewidth=2,\n        showline=True,\n        tickvals=['Data Analyst', 'Business Analyst'],  # Ensure clarity\n    ),\n\n    # Y-axis styling\n    yaxis=dict(\n        title=\"Number of Jobs\",\n        title_font=dict(size=18, color=\"#2D3436\"),\n        tickfont=dict(size=14, color=\"#636E72\"),\n        range=[0, df_top_industries['Job_Count'].max() * 1.2],  # Extended range\n        gridcolor=\"rgba(200, 200, 200, 0.3)\",\n        linecolor=\"#2D3436\",\n        linewidth=2,\n        showline=True\n    ),\n\n    # Legend styling\n    legend=dict(\n        title=\"Industry\",\n        font=dict(size=13, color=\"#2D3436\"),\n        bgcolor=\"rgba(255, 255, 255, 0.95)\",\n        bordercolor=\"#2D3436\",\n        borderwidth=1,\n        x=1.02,  # Position outside\n        y=0.5,\n        xanchor=\"left\",\n        yanchor=\"middle\",\n        traceorder=\"normal\",  # Ensure consistent ordering\n    ),\n\n    # Hover and interactivity\n    hovermode=\"closest\",\n    hoverlabel=dict(\n        bgcolor=\"rgba(255, 255, 255, 0.9)\",\n        font_size=13,\n        font_family=\"Poppins, sans-serif\",\n        font_color=\"#2D3436\",\n        bordercolor=\"#2D3436\",\n        align=\"left\"\n    ),\n\n    # Bar spacing\n    bargap=0.25,  # Add space between bars\n    barnorm=None,\n)\n\n# Customize the bars\nfig.update_traces(\n    marker=dict(\n        line=dict(width=1, color=\"#2D3436\"),  # Subtle border\n        # Add a slight gradient effect using opacity\n        opacity=0.9,\n    ),\n    text=df_top_industries['Job_Count'],  # Add labels on bars\n    textposition='outside',  # Place labels outside\n    textfont=dict(size=12, color=\"#2D3436\", family=\"Poppins, sans-serif\"),\n    texttemplate='%{text}',  # Show just the number\n    # Custom hover template\n    hovertemplate=\"&lt;b&gt;%{fullData.name}&lt;/b&gt;&lt;br&gt;Category: %{x}&lt;br&gt;Jobs: %{y}&lt;extra&gt;&lt;/extra&gt;\",\n)\n\n# Add a subtle gradient background effect (using shapes)\nfig.add_shape(\n    type=\"rect\",\n    x0=0, y0=0, x1=1, y1=1,\n    xref=\"paper\", yref=\"paper\",\n    fillcolor=\"rgba(220, 221, 255, 0.2)\",  # Very light gradient overlay\n    line=dict(width=0),\n    layer=\"below\"\n)\n\n# Add an annotation for the highest job count\nmax_job = df_top_industries.loc[df_top_industries['Job_Count'].idxmax()]\nfig.add_annotation(\n    x=max_job['Job_Category'],\n    y=max_job['Job_Count'] * 1.15,\n    text=f\"Top: {max_job['NAICS2_NAME_SHORT']}&lt;br&gt;{max_job['Job_Count']} Jobs\",\n    showarrow=True,\n    arrowhead=1,\n    ax=20,\n    ay=-40,\n    font=dict(size=13, color=\"#2D3436\", family=\"Poppins, sans-serif\"),\n    bgcolor=\"rgba(255, 255, 255, 0.9)\",\n    bordercolor=\"#2D3436\",\n    borderwidth=1,\n    borderpad=4\n)\n\n# Add a subtle shadow effect to the title (simulated with a duplicate text)\nfig.add_annotation(\n    x=0.5,\n    y=0.95,\n    xref=\"paper\",\n    yref=\"paper\",\n    text=\"Top 10 Industries Hiring Data & Business Analysts\",\n    showarrow=False,\n    font=dict(size=28, color=\"rgba(0, 0, 0, 0.05)\", family=\"Poppins, sans-serif\"),\n    xanchor=\"center\",\n    yanchor=\"top\",\n    yshift=-2,\n    xshift=2\n)\n\n                                                \n\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Define target industries\ntarget_industries = [\"Finance and Insurance\", \"Health Care and Social Assistance\"]\n\n# Filter the original DataFrame (df) instead of df_grouped\ndf_remote = eda[eda[\"NAICS2_NAME\"].isin(target_industries)]\n\n# Count occurrences of each remote type in these industries\ndf_remote_grouped = df_remote.groupby(\"REMOTE_TYPE_NAME\").size().reset_index(name=\"Count\")\n\n# Define a modern color palette\ncolor_map = {\n    \"Remote\": \"#6AB1E9\",  # Soft Sky Blue\n    \"On-Site\": \"#EF767A\",  # Soft Coral\n    \"Hybrid\": \"#49C6B7\"   # Teal-Green\n}\n\n# Create the pie chart\nfig = px.pie(df_remote_grouped, \n             names=\"REMOTE_TYPE_NAME\", \n             values=\"Count\", \n             title=\"Remote vs. On-Site Data Analyst Jobs in Finance & Healthcare\",\n             color=\"REMOTE_TYPE_NAME\", \n             color_discrete_map=color_map)\n\n# Beautify the layout\nfig.update_layout(\n    # Sizing and margins\n    autosize=True,\n    width=900,  # Compact width for pie charts\n    height=700,  # Taller height to accommodate title and legend\n    margin=dict(l=50, r=50, t=120, b=50),  # Adjusted margins for title\n\n    # Background styling\n    plot_bgcolor='rgba(240, 240, 245, 1)',  # Light gray background\n    paper_bgcolor='rgba(255, 255, 255, 1)',  # White paper background\n    font=dict(family=\"Poppins, sans-serif\", size=14, color=\"#2D3436\"),  # Modern font\n\n    # Title styling\n    title=dict(\n        text=\"Remote vs. On-Site Data Analyst Jobs in Finance & Healthcare\",\n        font=dict(size=24, color=\"#2D3436\", family=\"Poppins, sans-serif\"),\n        x=0.5,\n        xanchor=\"center\",\n        y=0.95,\n        yanchor=\"top\"\n    ),\n\n    # Legend styling\n    legend=dict(\n        title=\"Remote Type\",\n        font=dict(size=13, color=\"#2D3436\"),\n        bgcolor=\"rgba(255, 255, 255, 0.95)\",\n        bordercolor=\"#2D3436\",\n        borderwidth=1,\n        x=1.05,  # Position outside\n        y=0.5,\n        xanchor=\"left\",\n        yanchor=\"middle\"\n    ),\n\n    # Hover and interactivity\n    hovermode=\"closest\",\n    hoverlabel=dict(\n        bgcolor=\"rgba(255, 255, 255, 0.9)\",\n        font_size=13,\n        font_family=\"Poppins, sans-serif\",\n        font_color=\"#2D3436\",\n        bordercolor=\"#2D3436\"\n    ),\n\n    # Add a subtle gradient background effect\n    shapes=[\n        dict(\n            type=\"rect\",\n            x0=0, y0=0, x1=1, y1=1,\n            xref=\"paper\", yref=\"paper\",\n            fillcolor=\"rgba(220, 221, 255, 0.2)\",  # Light gradient overlay\n            line=dict(width=0),\n            layer=\"below\"\n        )\n    ]\n)\n\n# Customize the pie chart slices\nfig.update_traces(\n    # Add percentages and labels\n    textinfo=\"percent+label\",\n    textfont=dict(size=14, color=\"#2D3436\", family=\"Poppins, sans-serif\"),\n    textposition=\"inside\",  # Place labels inside for a cleaner look\n\n    # Add a subtle border to slices\n    marker=dict(\n        line=dict(color=\"#2D3436\", width=1.5)\n    ),\n\n    # Pull out the largest slice slightly for emphasis\n    pull=[0.1 if count == df_remote_grouped['Count'].max() else 0 for count in df_remote_grouped['Count']],\n\n    # Add a slight opacity for a softer look\n    opacity=0.9,\n\n    # Custom hover template\n    hovertemplate=\"&lt;b&gt;%{label}&lt;/b&gt;&lt;br&gt;Count: %{value}&lt;br&gt;Percentage: %{percent}&lt;extra&gt;&lt;/extra&gt;\",\n\n    # Add a rotation for better presentation\n    rotation=45,\n\n    # Add a subtle shadow effect to slices (simulated with opacity and border)\n    sort=False  # Keep the order as in the data\n)\n\n# Add an annotation for the largest slice\nmax_slice = df_remote_grouped.loc[df_remote_grouped['Count'].idxmax()]\nfig.add_annotation(\n    x=0.5,\n    y=0.1,\n    xref=\"paper\",\n    yref=\"paper\",\n    text=f\"Dominant Type: {max_slice['REMOTE_TYPE_NAME']}&lt;br&gt;{max_slice['Count']} Jobs ({fig.data[0]['values'].tolist().index(max_slice['Count'])*100/sum(fig.data[0]['values']):.1f}%)\",\n    showarrow=False,\n    font=dict(size=13, color=\"#2D3436\", family=\"Poppins, sans-serif\"),\n    bgcolor=\"rgba(255, 255, 255, 0.9)\",\n    bordercolor=\"#2D3436\",\n    borderwidth=1,\n    borderpad=4\n)\n\n# Add a shadow effect to the title (simulated with a duplicate text)\nfig.add_annotation(\n    x=0.5,\n    y=0.95,\n    xref=\"paper\",\n    yref=\"paper\",\n    text=\"Remote vs. On-Site Data Analyst Jobs in Finance & Healthcare\",\n    showarrow=False,\n    font=dict(size=24, color=\"rgba(0, 0, 0, 0.05)\", family=\"Poppins, sans-serif\"),\n    xanchor=\"center\",\n    yanchor=\"top\",\n    yshift=-2,\n    xshift=2\n)\n\n                                                \n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 1) Trim out the 1–99th percentile so outliers don’t skew the means\nlow, high = eda['SALARY'].quantile([0.01, 0.99])\neda_trim = eda[(eda['SALARY'] &gt;= low) & (eda['SALARY'] &lt;= high)]\n\n# 2) Compute mean salary by remote type\nmeans = eda_trim.groupby('REMOTE_TYPE_NAME')['SALARY'].mean().loc[['Remote', 'Not Remote', 'Hybrid Remote']]\n\n# 3) Plot with value labels\nplt.figure(figsize=(10, 7))\nbars = means.plot.bar(color=['#4C72B0', '#55A868', '#C44E52'])\nplt.title('Average Salary by Remote Type (1–99th pct)')\nplt.ylabel('Mean Annual Salary')\nplt.xticks(rotation=0)\n\n# Add value labels on top of each bar\nfor bar in bars.patches:\n    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{int(bar.get_height())}', \n             ha='center', va='bottom')\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Trim outliers\nlow, high = eda['SALARY'].quantile([0.01, 0.99])\neda_trim = eda[(eda['SALARY'] &gt;= low) & (eda['SALARY'] &lt;= high)]\n\n# Plot histogram\nplt.figure(figsize=(8, 6))\nplt.hist(eda_trim['SALARY'], bins=30, color='#4C72B0', edgecolor='black')\nplt.title('Salary Distribution (1–99th pct)')\nplt.xlabel('Annual Salary')\nplt.ylabel('Frequency')\n\nText(0, 0.5, 'Frequency')\n\n\n\n\n\n\n\n\n\n\nimport plotly.express as px\nimport pandas as pd\n\n# Define target industries (same as before)\ntarget_industries = [\"Finance and Insurance\", \"Health Care and Social Assistance\"]\n\n# Filter the original DataFrame for these industries\n# Assuming 'df' has a 'SALARY' column (from our regression analysis context)\ndf_target = eda[eda[\"NAICS2_NAME\"].isin(target_industries)].copy()\n\n# Map DATA_ANALYST_JOB to meaningful labels\ndf_target['Job_Category'] = df_target['DATA_ANALYST_JOB'].map({True: 'Data Analyst', False: 'Business Analyst'})\n\n# Group by Job_Category and REMOTE_TYPE_NAME, calculate average salary\ndf_salary_grouped = df_target.groupby(['Job_Category', 'REMOTE_TYPE_NAME'])['SALARY'].mean().reset_index(name='Avg_Salary')\n\n# Create a grouped bar chart\nfig = px.bar(df_salary_grouped,\n             x='Job_Category',\n             y='Avg_Salary',\n             color='REMOTE_TYPE_NAME',\n             title=\"Average Salary by Remote Type and Job Category (Finance & Healthcare)\",\n             labels={'Job_Category': 'Job Category', 'Avg_Salary': 'Average Salary ($)', 'REMOTE_TYPE_NAME': 'Remote Type'},\n             barmode='group',\n             color_discrete_map={\"Remote\": \"#6AB1E9\", \"On-Site\": \"#EF767A\", \"Hybrid\": \"#49C6B7\"})\n\n# Beautify the layout\nfig.update_layout(\n    width=900,\n    height=600,\n    plot_bgcolor='rgba(240, 240, 245, 1)',\n    paper_bgcolor='rgba(255, 255, 255, 1)',\n    font=dict(family=\"Poppins, sans-serif\", size=14, color=\"#2D3436\"),\n    title=dict(\n        text=\"Average Salary by Remote Type and Job Category (Finance & Healthcare)\",\n        font=dict(size=24, color=\"#2D3436\"),\n        x=0.5,\n        xanchor=\"center\"\n    ),\n    xaxis=dict(\n        title=\"Job Category\",\n        title_font=dict(size=18),\n        tickfont=dict(size=14)\n    ),\n    yaxis=dict(\n        title=\"Average Salary ($)\",\n        title_font=dict(size=18),\n        tickfont=dict(size=14),\n        gridcolor=\"rgba(200, 200, 200, 0.3)\"\n    ),\n    legend=dict(\n        title=\"Remote Type\",\n        font=dict(size=13),\n        x=1.05,\n        y=0.5,\n        xanchor=\"left\",\n        yanchor=\"middle\"\n    ),\n    bargap=0.2\n)\n\n# Add value labels on top of bars\nfig.update_traces(\n    text=df_salary_grouped['Avg_Salary'].round(2),\n    textposition='outside',\n    textfont=dict(size=12, color=\"#2D3436\")\n)"
  },
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "This page presents our data cleaning and prepping part.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\ndf = pd.read_csv(\"./data/lightcast_job_postings.csv\")\n\ncolumns_to_keep = [\n    'COMPANY', 'LOCATION', 'POSTED', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS_NAME',\n    'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'TITLE', 'SKILLS',\n    'SPECIALIZED_SKILLS', 'CERTIFICATIONS', 'COMMON_SKILLS', 'SOFTWARE_SKILLS',\n    'SOC_2021_4_NAME', 'NAICS_2022_6', 'NAICS2_NAME', 'REMOTE_TYPE_NAME',\n    'SALARY', 'TITLE_NAME', 'SKILLS_NAME', 'SPECIALIZED_SKILLS_NAME'\n]\n\neda_data = df[columns_to_keep]\n\n\nmsno.heatmap(eda_data)\nplt.title(\"Missing Values Heatmap\")\nplt.savefig(\"figures/missingno_heatmap.svg\", format='svg', bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\nif \"SALARY\" in eda_data.columns:\n    eda_data[\"SALARY\"].fillna(eda_data[\"SALARY\"].median(), inplace=True)\nelse:\n    print(\"⚠️ Warning: 'SALARY' column not found in dataframe!\")\n\nif \"COMPANY\" in eda_data.columns:\n    eda_data[\"COMPANY\"].fillna(\"Unknown\", inplace=True)\nelse:\n    print(\"⚠️ Warning: 'COMPANY' column not found in dataframe!\")\n\n    # Fill numeric columns with mean\nnum_cols = eda_data.select_dtypes(include='number').columns\nfor col in num_cols:\n    if eda_data[col].isnull().sum() &gt; 0:\n        eda_data[col].fillna(eda_data[col].mean(), inplace=True)\n\n# Fill categorical columns with mode\ncat_cols = eda_data.select_dtypes(include='object').columns\nfor col in cat_cols:\n    if eda_data[col].isnull().sum() &gt; 0:\n        eda_data[col].fillna(eda_data[col].mode()[0], inplace=True)\n\nprint(\"✅ Remaining missing values filled based on column type.\")\n\n\neda_data.dropna(thresh=len(eda_data) * 0.5, axis=1, inplace=True)\n\n\nprint(\"✅ Missing value handling complete.\")\n\n# delete duplicates\neda_data = eda_data.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"])\neda_data.to_csv(\"./data/eda_data.csv\", index=False)\n\nprint(eda_data.isnull().sum())\n\n/var/folders/pm/h80kxhdj497chd0j6d72z7km0000gn/T/ipykernel_27561/1295971972.py:2: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n/var/folders/pm/h80kxhdj497chd0j6d72z7km0000gn/T/ipykernel_27561/1295971972.py:2: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/var/folders/pm/h80kxhdj497chd0j6d72z7km0000gn/T/ipykernel_27561/1295971972.py:7: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n/var/folders/pm/h80kxhdj497chd0j6d72z7km0000gn/T/ipykernel_27561/1295971972.py:7: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/var/folders/pm/h80kxhdj497chd0j6d72z7km0000gn/T/ipykernel_27561/1295971972.py:15: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n/var/folders/pm/h80kxhdj497chd0j6d72z7km0000gn/T/ipykernel_27561/1295971972.py:15: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/var/folders/pm/h80kxhdj497chd0j6d72z7km0000gn/T/ipykernel_27561/1295971972.py:21: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n/var/folders/pm/h80kxhdj497chd0j6d72z7km0000gn/T/ipykernel_27561/1295971972.py:21: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/var/folders/pm/h80kxhdj497chd0j6d72z7km0000gn/T/ipykernel_27561/1295971972.py:26: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n✅ Remaining missing values filled based on column type.\n✅ Missing value handling complete.\nCOMPANY                    0\nLOCATION                   0\nPOSTED                     0\nMIN_EDULEVELS_NAME         0\nMAX_EDULEVELS_NAME         0\nMIN_YEARS_EXPERIENCE       0\nMAX_YEARS_EXPERIENCE       0\nTITLE                      0\nSKILLS                     0\nSPECIALIZED_SKILLS         0\nCERTIFICATIONS             0\nCOMMON_SKILLS              0\nSOFTWARE_SKILLS            0\nSOC_2021_4_NAME            0\nNAICS_2022_6               0\nNAICS2_NAME                0\nREMOTE_TYPE_NAME           0\nSALARY                     0\nTITLE_NAME                 0\nSKILLS_NAME                0\nSPECIALIZED_SKILLS_NAME    0\ndtype: int64"
  }
]