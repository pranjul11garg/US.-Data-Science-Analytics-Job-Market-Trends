{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Data Analysis\n",
        "subtitle: Comprehensive Data Cleaning & Exploratory Analysis of Job Market Trends\n",
        "author:\n",
        "  - name: Binderiya Dugersuren\n",
        "    affiliations:\n",
        "      - id: U83856370\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "  - name: Pranjul Garg\n",
        "    affiliations:\n",
        "      - id: U39153801\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "  - name: Pratham Kabra\n",
        "    affiliations:\n",
        "      - id: U64612957\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "  - name: Panyang Xiang\n",
        "    affiliations:\n",
        "      - id: U64612957\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "bibliography: references.bib\n",
        "csl: csl/econometrica.csl\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    number-sections: true\n",
        "    df-print: paged\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Introduction\n",
        "This document outlines the data cleaning process, including:\n",
        "- Handling missing values\n",
        "- Dropping unnecessary columns\n",
        "- Deduplicating records\n"
      ],
      "id": "6dd7111c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# columns drop\n",
        "import pandas as pd\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define file details\n",
        "file_id = \"1VNBTxArDMN2o9fJBDImaON6YUAyJGOU6\"  # Your Google Drive File ID\n",
        "zip_file = \"lightcast_job_postings.zip\"  # Name of the downloaded ZIP file\n",
        "csv_file = \"./data/lightcast_job_postings.csv\"  # Path to the CSV file\n",
        "\n",
        "# Step 1: Download the Dataset\n",
        "print(\"Downloading the dataset...\")\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", zip_file, quiet=False)\n",
        "\n",
        "# Step 2: Unzip the File\n",
        "print(\"Extracting files...\")\n",
        "with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"./data\")  # Extracts to 'data' directory\n",
        "\n",
        "# Step 3: Read the CSV File\n",
        "print(\"Reading the CSV file...\")\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Display dataset info\n",
        "print(\"Dataset Loaded Successfully!\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"Available columns in dataset:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "columns_to_drop = [\n",
        "    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n",
        "    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n",
        "    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n",
        "]\n",
        "\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "print(\"Dropped unnecessary columns.\")\n",
        "print(df.columns)\n",
        "\n",
        "# handle missing value\n",
        "print(\"Missing values before cleaning:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "import missingno as msno\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check column names\n",
        "df.columns = df.columns.str.upper().str.strip()  # Normalize column names\n",
        "print(df.columns)  # Debugging step\n",
        "\n",
        "# Visualize missing data\n",
        "msno.heatmap(df)\n",
        "plt.title(\"Missing Values Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# Drop columns with >50% missing values\n",
        "df.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n",
        "\n",
        "# Check if \"SALARY\" exists before filling missing values\n",
        "if \"SALARY\" in df.columns:\n",
        "    df[\"SALARY\"].fillna(df[\"SALARY\"].median(), inplace=True)\n",
        "else:\n",
        "    print(\"⚠️ Warning: 'SALARY' column not found in dataframe!\")\n",
        "\n",
        "# Check if \"INDUSTRY\" exists before filling missing values\n",
        "if \"INDUSTRY\" in df.columns:\n",
        "    df[\"INDUSTRY\"].fillna(\"Unknown\", inplace=True)\n",
        "else:\n",
        "    print(\"⚠️ Warning: 'INDUSTRY' column not found in dataframe!\")\n",
        "\n",
        "print(\"✅ Missing value handling complete.\")\n",
        "\n",
        "\n",
        "# delete duplicates\n",
        "df = df.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"])\n",
        "print(\"Duplicates removed.\")"
      ],
      "id": "a1d73d61",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/begiii/Library/Python/3.13/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}