[
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Cleaning",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport plotly.express as px\nimport numpy as np\nimport plotly.graph_objects as go\n\ndf = pd.read_parquet(\"data/lightcast.parquet\")\n\n\ncolumns_to_keep = [\n    'COMPANY', 'LOCATION', 'POSTED', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS_NAME',\n    'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'TITLE', 'SKILLS',\n    'SPECIALIZED_SKILLS', 'CERTIFICATIONS', 'COMMON_SKILLS', 'SOFTWARE_SKILLS',\n    'SOC_2021_4_NAME', 'NAICS_2022_6', 'NAICS2_NAME', 'REMOTE_TYPE_NAME',\n    'SALARY', 'TITLE_NAME', 'SKILLS_NAME', 'SPECIALIZED_SKILLS_NAME', 'BODY'\n]\neda_data = df[columns_to_keep]\n\n\n\n\nCode\nmissing_matrix = eda_data.isnull().astype(int)\ncorr = missing_matrix.corr().round(2)\n\nmask = np.triu(np.ones(corr.shape), k=1).astype(bool)\nmasked_corr = corr.mask(mask)\n\ntext_labels = masked_corr.astype(str)\ntext_labels[masked_corr.isna()] = \"\"\n\n# plot\nfig = go.Figure(data=go.Heatmap(\n    z=masked_corr.values,\n    x=masked_corr.columns,\n    y=masked_corr.index,\n    text=text_labels.values,\n    texttemplate=\"%{text}\",\n    colorscale=\"Blues\",\n    colorbar=dict(title=\"Missing Corr\"),\n    zmin=0,\n    zmax=1,\n    hoverinfo='skip'\n))\n\nfig.update_layout(\n    title=\"Clean Triangle Missing Value Correlation Heatmap\",\n    xaxis_tickangle=45,\n    width=850,\n    height=600,\n    margin=dict(t=50, l=80, r=50, b=80),\n    font=dict(size=8),\n    plot_bgcolor='white'\n)\n\nfig.update_yaxes(autorange=\"reversed\")\n\nfig.write_html(\n    'figures/data_cleaning_plot1.html',\n    include_plotlyjs='cdn',\n    full_html=False)\n\n\n\n\nThis triangle heatmap visualizes the correlation of missing values between different columns in the dataset. Each square represents how often two columns are missing together, with darker blue indicating a stronger relationship. Most of the values are very high (close to 1.0), suggesting that when one column is missing, others are often missing too ‚Äî especially among skill-related fields like SKILLS, SPECIALIZED_SKILLS, and SOFTWARE_SKILLS, which are likely part of the same job posting metadata.\nThis pattern indicates that missingness is not random, but structured ‚Äî possibly due to differences in how job descriptions are recorded across roles or industries. For example, a job with no software skill tags might also lack common skills or NAICS codes, hinting at data input gaps rather than actual job content differences. Recognizing these correlations is helpful for choosing imputation strategies or deciding whether to drop certain rows or columns entirely during preprocessing.\n\n\nCode\nif \"SALARY\" in eda_data.columns:\n    eda_data[\"SALARY\"].fillna(eda_data[\"SALARY\"].median(), inplace=True)\nelse:\n    print(\"Warning: 'SALARY' column not found in dataframe!\")\n\nif \"COMPANY\" in eda_data.columns:\n    eda_data[\"COMPANY\"].fillna(\"Unknown\", inplace=True)\nelse:\n    print(\"Warning: 'COMPANY' column not found in dataframe!\")\n\n    # Fill numeric columns with mean\nnum_cols = eda_data.select_dtypes(include='number').columns\nfor col in num_cols:\n    if eda_data[col].isnull().sum() &gt; 0:\n        eda_data[col].fillna(eda_data[col].mean(), inplace=True)\n\n# Fill categorical columns with mode\ncat_cols = eda_data.select_dtypes(include='object').columns\nfor col in cat_cols:\n    if eda_data[col].isnull().sum() &gt; 0:\n        eda_data[col].fillna(eda_data[col].mode()[0], inplace=True)\n\neda_data.dropna(thresh=len(eda_data) * 0.5, axis=1, inplace=True)\n\n\n# delete duplicates\neda_data = eda_data.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\",\"BODY\"])\neda_data['BODY'] = eda_data['BODY'].str.slice(0, 1000)\neda_data['BODY'] = eda_data['BODY'].astype(str)\neda_data['COMPANY'] = eda_data['COMPANY'].astype(str)\n\n\n\n\nCode\nimport pandas as pd\neda_data.to_parquet('data/eda.parquet', engine='pyarrow', compression='gzip')"
  },
  {
    "objectID": "analytics_model.html",
    "href": "analytics_model.html",
    "title": "Analytics Model",
    "section": "",
    "text": "Code\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import adjusted_rand_score\neda = pd.read_parquet(\"data/eda.parquet\")\n\n\n\n\nCode\nfeatures = eda[['SALARY', 'MAX_YEARS_EXPERIENCE', 'MIN_YEARS_EXPERIENCE']].copy()\n\nfor col in ['MAX_YEARS_EXPERIENCE', 'MIN_YEARS_EXPERIENCE', 'SALARY']:\n    features[col] = pd.to_numeric(features[col], errors='coerce')\n\nfeatures = features.dropna()\n\nscaler = StandardScaler()\nX = scaler.fit_transform(features)\n\nkmeans = KMeans(n_clusters=4, random_state=688)\neda.loc[features.index, 'Cluster'] = kmeans.fit_predict(X)\n\ntrue_labels = eda.loc[features.index, 'SOC_2021_4_NAME']\ntrue_labels_encoded = LabelEncoder().fit_transform(true_labels)\n\nari = adjusted_rand_score(true_labels_encoded, eda.loc[features.index, 'Cluster'])\n\n\n\n\nCode\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom IPython.display import HTML\nimport numpy as np\n\n# 1) Build the DataFrame\ndf_plot = features.copy()\ndf_plot['Cluster'] = eda.loc[features.index, 'Cluster']\n\n# 1.1) Create a log salary column for better scaling\ndf_plot['Log_SALARY'] = np.log1p(df_plot['SALARY'])  # log(1+salary), avoid log(0)\n\n# 2) Create an interactive Plotly Figure\nfig = px.scatter(\n    df_plot,\n    x='Log_SALARY',  # üëà use log salary instead of salary\n    y='MAX_YEARS_EXPERIENCE',\n    color='Cluster',\n    title=\"KMeans Clustering by Log(Salary) and Max Years Experience\",\n    labels={\n        'Log_SALARY': 'Log(Salary)',\n        'MAX_YEARS_EXPERIENCE': 'Max Years Experience',\n        'Cluster': 'Cluster'\n    },\n    width=800,\n    height=600,\n)\n\nfig\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n&lt;iframe src=‚Äú/figures/analytics_plot1.html‚Äù width=‚Äú100%‚Äù width=‚Äú100%‚Äù style=‚Äúborder:none; height:90vh; &gt;\nHere we have 4 cluster groups. Group 0, which represent as green have lower salary, mostly under 150k, and max years experience in 2-5 years, it is likely Likely junior to mid-level employees with moderate pay. Group 1 with orange, has medium to high salary, wide range from $100k‚Äì$500k and with narrow range ~3 years, they are suggests specialized or high-paying roles with short experience ‚Äî possibly fast-track promotions or high-demand fields. cluster 2 are low salary and experience from 0-4 years, they are clearly entry level employee. cluster 3 has medium salary, mostly under 200k with higher experiences, like 6-13 eyars. They probably are senior professionals with more experience but not the highest salaries.\n\n\nCode\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport plotly.graph_objects as go\n\n# Prepare features & target\nfeatures = eda[['MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE']].apply(pd.to_numeric, errors='coerce')\nfeatures = features.dropna()\nX = features\ny = eda.loc[X.index, 'SALARY']\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=688)\n\n# Fit model & predict\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n# Metrics (optional, but handy)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nprint(f\"MSE: {mse:.2f}, R¬≤: {r2:.3f}\")\n\n# Define min/max for the identity line\nmin_val = y_test.min()\nmax_val = y_test.max()\n\n\nMSE: 758547543.20, R¬≤: 0.096\n\n\n\n\nCode\nimport numpy as np\nimport plotly.graph_objects as go\n\n# Apply log transform\ny_test_log = np.log1p(y_test)\ny_pred_log = np.log1p(y_pred)\n\n# Plot\nfig = go.Figure([\n    go.Scatter(\n        x=y_test_log,\n        y=y_pred_log,\n        mode='markers',\n        marker=dict(color='skyblue', opacity=0.6),\n        name='Predicted vs Actual (Log Scale)'\n    ),\n    go.Scatter(\n        x=[min(y_test_log), max(y_test_log)],\n        y=[min(y_test_log), max(y_test_log)],\n        mode='lines',\n        line=dict(color='red', dash='dash'),\n        name='Ideal Fit'\n    )\n])\n\nfig.update_layout(\n    autosize=True,\n    height=400,\n    title=\"Predicted vs Actual Salary (Log Scale)\",\n    xaxis_title=\"Actual Log(Salary)\",\n    yaxis_title=\"Predicted Log(Salary)\",\n    margin=dict(l=20, r=20, t=50, b=20)\n)\n\nfig.write_html(\n    \"figures/analytics_plot2.html\",\n    full_html=False,\n    include_plotlyjs=\"cdn\",\n    config={\"responsive\": True}\n)\n\nfig.show()\n\n\n                            \n                                            \n\n\n&lt;iframe src=‚Äú/figures/analytics_plot2.html‚Äù width=‚Äú100%‚Äù style=‚Äúborder:none; height:90vh; &gt;\nThis plot shows the Actual vs.¬†Predicted Salary using a multiple linear regression model. The blue dots represent individual predictions, and the red dashed line is the ideal line where predicted = actual. Since most points lie very close to the red line, it means your model predicts salary very accurately, with minimal error and strong linear fit ‚Äî likely reflected in a high R¬≤ score near 1.0."
  },
  {
    "objectID": "skill_gap.html",
    "href": "skill_gap.html",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "Code\nimport pandas as pd\ndf = pd.read_parquet(\"data/eda.parquet\")"
  },
  {
    "objectID": "skill_gap.html#group-11-skill",
    "href": "skill_gap.html#group-11-skill",
    "title": "Skill Gap Analysis",
    "section": "Group 11 Skill",
    "text": "Group 11 Skill\n\n\nCode\nimport pandas as pd\n\nskills_data = {\n    \"Name\": [\"Binderiya\", \"Pranjul\", \"Pratham\", \"Panyang\"],\n    \"Python\": [4, 4, 5, 3],\n    \"SQL\": [4, 4, 5, 4],\n    \"Machine Learning\": [2, 3, 2, 2],\n    \"PySpark\": [3, 3, 3, 3],\n    \"Excel\": [4, 5, 5, 4],\n    \"Data Visualization\": [5, 5, 3, 3],\n    \"Power Bi/ Tableau\": [4, 5, 3, 4],\n    \"Version Control Git\": [4, 4, 3, 3],\n    \"ETL/Data pipeline\": [3, 2, 1, 2],\n    \"Communication\": [4, 4, 5, 3],\n    \"Project Management\": [5, 5, 5, 3],\n    \"Cloud Computing\": [4, 4, 2, 2]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nPySpark\nExcel\nData Visualization\nPower Bi/ Tableau\nVersion Control Git\nETL/Data pipeline\nCommunication\nProject Management\nCloud Computing\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinderiya\n4\n4\n2\n3\n4\n5\n4\n4\n3\n4\n5\n4\n\n\nPranjul\n4\n4\n3\n3\n5\n5\n5\n4\n2\n4\n5\n4\n\n\nPratham\n5\n5\n2\n3\n5\n3\n3\n3\n1\n5\n5\n2\n\n\nPanyang\n3\n4\n2\n3\n4\n3\n4\n3\n2\n3\n3\n2\n\n\n\n\n\n\n\n\n\nCode\nimport plotly.express as px\n\nfig = px.imshow(\n    df_skills,\n    text_auto=True,                \n    color_continuous_scale=\"YlGnBu\",\n    aspect=\"auto\"                 \n)\n\nfig.update_layout(\n    title=\"Team Skill Levels Heatmap\",\n    xaxis_title=\"Skills\",\n    yaxis_title=\"Team Members\",\n    width=700,\n    height=400,\n    margin=dict(l=50, r=20, t=50, b=50)\n)\n\nfig.write_html(\n    \"figures/skill_gap_plot1.html\",\n    include_plotlyjs=\"cdn\",\n    full_html=False\n)\n\n\n\n\n\n\nCode\nimport plotly.graph_objects as go\nfrom IPython.display import IFrame\nfig = go.Figure()\n\nfor name in df_skills.index:\n    values = df_skills.loc[name].tolist()\n    values += values[:1]  # close the loop\n    fig.add_trace(go.Scatterpolar(\n        r=values,\n        theta=df_skills.columns.tolist() + [df_skills.columns[0]],\n        fill='toself',\n        name=name\n    ))\n\nfig.update_layout(\n    polar=dict(radialaxis=dict(visible=True, range=[0, 5])),\n    showlegend=True,\n    title='Team Skills Radar Chart'\n)\n\nfig.write_html(\n    \"figures/skill_gap_plot2.html\",\n    include_plotlyjs=\"cdn\",\n    full_html=False\n)\n\n\n\n\n\nInteractive Radar Chart\nFrom this radar chart visualization we can see that our team has a lot of room for improvement for skills like PySpark and Machine Learning. Also we can see that not a lot of our team mates are confident in their skills in Cloud Computing and ETL."
  },
  {
    "objectID": "skill_gap.html#top-skills",
    "href": "skill_gap.html#top-skills",
    "title": "Skill Gap Analysis",
    "section": "Top Skills",
    "text": "Top Skills\n\n\nCode\nkeywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n            'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n            'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n            'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n\nmatch = lambda col: df[col].str.contains('|'.join(keywords), case=False, na=False)\n\ndf['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n             | match('SKILLS_NAME') \\\n             | match('SPECIALIZED_SKILLS_NAME') \ndf['DATA_ANALYST_JOB'].value_counts()\n\n\nDATA_ANALYST_JOB\nFalse    38258\nTrue     33083\nName: count, dtype: int64\n\n\n\n\nCode\nimport ast\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n# Safely apply literal_eval only to non-null values\ndf['SKILLS'] = df['SKILLS_NAME'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n\n\ndata_skills = df[df['DATA_ANALYST_JOB']]['SKILLS'].explode().value_counts().reset_index()\ndata_skills.columns = ['Skill', 'Count']\n\nfig = px.bar(data_skills, x='Skill', y='Count',\n             title=\"Top Skills\",\n             labels={'Skill': 'Skill Name', 'Count': 'Frequency'},\n             color='Skill')\ndf_skills.index = df_skills.index.str.strip()\n\n\n\n\nCode\nfrom collections import defaultdict\n\n# Lowercase everything\nteam_skills = [s.lower().strip() for s in df_skills.columns]\njob_demand_raw = data_skills.copy()\njob_demand_raw['Skill'] = job_demand_raw['Skill'].str.lower().str.strip()\n\n# New dict to map cleaned team skill to total count from job postings\nskill_demand_map = defaultdict(int)\n\nfor _, row in job_demand_raw.iterrows():\n    skill_in_posting = row['Skill']\n    count = row['Count']\n    for team_skill in team_skills:\n        if team_skill in skill_in_posting:\n            skill_demand_map[team_skill] += count\n\n\n\n\nCode\nteam_skills = [s.strip().lower() for s in df_skills.columns]\nprint(\"Team skills:\", team_skills)\nprint(job_demand_raw['Skill'].head(10).tolist())\nfor skill_text in job_demand_raw['Skill'].head(10):\n    for team_skill in team_skills:\n        if team_skill in skill_text:\n            print(f\" '{team_skill}' found in: '{skill_text}'\")\n\n\nTeam skills: ['python', 'sql', 'machine learning', 'pyspark', 'excel', 'data visualization', 'power bi/ tableau', 'version control git', 'etl/data pipeline', 'communication', 'project management', 'cloud computing']\n['data analysis', 'sql (programming language)', 'communication', 'management', 'python (programming language)', 'tableau (business intelligence software)', 'dashboard', 'computer science', 'problem solving', 'power bi']\n 'sql' found in: 'sql (programming language)'\n 'communication' found in: 'communication'\n 'python' found in: 'python (programming language)'\n\n\n\n\nCode\nfor _, row in job_demand_raw.iterrows():\n    skill_text = row['Skill']\n    count = row['Count']\n    for team_skill in team_skills:\n        if team_skill in skill_text:  # no regex, just substring\n            skill_demand_map[team_skill] += count\n\njob_demand = pd.Series(skill_demand_map)\nprint(job_demand)\n\n\nsql                   48590\ncommunication         48980\npython                22364\nexcel                 19182\ndata visualization    14894\nproject management    14988\nmachine learning       8520\ncloud computing        2610\npyspark                1026\ndtype: int64\n\n\n\n\nCode\njob_demand = pd.Series(skill_demand_map)\njob_demand.name = \"Count\"\nteam_avg = df_skills.mean()\nteam_avg.index = team_avg.index.str.strip().str.lower() \n# Now match only overlapping skills\ncommon_skills = job_demand.index.intersection(team_avg.index)\nteam_avg = team_avg[common_skills]\njob_demand = job_demand[common_skills]\n\n# Normalize job demand\njob_demand_normalized = 5 * (job_demand / job_demand.max())\njob_demand_normalized.name = \"Job Demand (Normalized)\"\n\n# Combine\ncomparison_df = pd.concat([team_avg, job_demand_normalized], axis=1)\ncomparison_df.columns = [\"Team Average Skill\", \"Job Demand (Normalized)\"]\ncomparison_df[\"Skill Gap\"] = comparison_df[\"Job Demand (Normalized)\"] - comparison_df[\"Team Average Skill\"]\ncomparison_df.sort_values(\"Skill Gap\", ascending=False, inplace=True)\n\ncomparison_df\n\n\n\n\n\n\n\n\n\nTeam Average Skill\nJob Demand (Normalized)\nSkill Gap\n\n\n\n\ncommunication\n4.00\n5.000000\n1.000000\n\n\nsql\n4.25\n4.960188\n0.710188\n\n\nmachine learning\n2.25\n0.869743\n-1.380257\n\n\npython\n4.00\n2.282973\n-1.717027\n\n\ndata visualization\n4.00\n1.520416\n-2.479584\n\n\nexcel\n4.50\n1.958146\n-2.541854\n\n\ncloud computing\n3.00\n0.266435\n-2.733565\n\n\npyspark\n3.00\n0.104737\n-2.895263\n\n\nproject management\n4.50\n1.530012\n-2.969988\n\n\n\n\n\n\n\n\n\nCode\ncomparison_df = comparison_df.reset_index().rename(columns={\"index\": \"Skill\"})\n\n\n\n\nCode\nimport plotly.express as px\n\nfig = px.bar(\n    comparison_df,\n    x='Skill',\n    y='Skill Gap',\n    color='Skill Gap',\n    color_continuous_scale='RdBu_r',\n    title='Skill Gaps: Job Market Expectations vs. Team Capability',\n    labels={'Skill Gap': 'Gap (Job Demand - Team Skill)', 'Skill': 'Skill'},\n)\n\nfig.add_hline(y=0, line_dash='dash')\nfig.update_layout(\n    xaxis_tickangle=-45,\n    yaxis_title='Gap (Positive = Market expects more)',\n    font=dict(size=13),\n    height=500,\n    plot_bgcolor='white',\n)\nfig.write_html(\n    \"figures/skill_gap_plot3.html\",\n    include_plotlyjs=\"cdn\",\n    full_html=False\n)\n\n\n\n\nThis bar chart compares our team‚Äôs average proficiency in key data-related skills against job market expectations. Skills with positive values (like communication and SQL) indicate areas where market demand exceeds our current capabilities. On the other hand, negative values highlight areas where the team is ahead or closely aligned with market needs. Notably, skills like Python, cloud computing, and project management show the largest gaps, suggesting priority areas for upskilling."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Next Normal: AI-Driven Analytics in Action",
    "section": "",
    "text": "State of the Data Industry \n\n\n ¬†Ethics & Responsible AI \n\n\n ¬†Scaling Data Platforms \n\n\n ¬†Future Tech & Innovation \n\n\n\n\nGoal of the Project:\nIn this research project, we wanted explore how the fields of Business Analytics, Data Science, and Machine Learning are evolving in 2024. With industries rapidly embracing AI technologies, understanding hiring trends and skill demands has become essential for students and professionals alike.\nOur Research Question: - What are the most in-demand skills for data science, business analytics, and ML roles?\n\nHave job descriptions evolved in 2024 to require more AI/ML expertise?\nWhat industries are hiring the most data scientists and why?\nWhat is the career outlook for business analytics professionals?\n\nTo answer these questions, we analyzed a large dataset of real job postings sourced from Lightcast. We applied data cleaning, exploratory analysis, skill extraction, and machine learning classification techniques to identify emerging trends and skill gaps.\n\nWhy This Matters\nThe rise of artificial intelligence (AI) and automation is not only transforming industries, it is changing the very skills required to succeed in the job market. Recent research shows that 86% of workers express concerns about AI-driven job displacement (Samuels (2024)), while businesses simultaneously seek employees who can work alongside AI tools and leverage data-driven insights to create value (Gartner (2024)).\nAs companies invest heavily in AI technologies ‚Äî with an estimated $2.5 million average per organization in 2024 (Gartner (2024)) professionals skilled in machine learning, cloud computing, Python, and data visualization will be better positioned for future career success.\nArtificial intelligence and machine learning are transforming workforce demands across industries. In 2024, companies are projected to invest over $2.5 million on average into AI technologies (Gartner (2024)), reshaping job descriptions to require AI and data science skills.\nFar from replacing all jobs, AI is reshaping roles to focus on higher-value, decision-driven tasks (White (2024); Richardson (2024)). As a result, professionals who upskill in AI, machine learning, and data analytics are better positioned for career advancement in a future where AI-human collaboration is key.\nOur project investigates these trends through real-world job posting analysis ‚Äî revealing how demand for skills is shifting and where opportunities are growing.\n\n\n\nKey Trends Shaping Data Science and Analytics Careers\n\nTop Skills\nOur analysis found that Python, Machine Learning, and Cloud Computing consistently rank among the top-requested skills in job postings. Employers are seeking candidates who can not only analyze data but also deploy models and build scalable solutions. Python remains the foundational language across roles, while machine learning capabilities and cloud platform expertise such as AWS or Azure offer clear competitive advantages.\n\n\nAI Skills Now a Must\nCompared to prior years, 2024 job postings show a notable shift: companies are explicitly requesting skills like Artificial Intelligence, Machine Learning, and Deep Learning. This highlights how AI technologies are no longer ‚Äúnice-to-have‚Äù but are becoming core to business operations. Candidates without exposure to AI tools or methods risk being overlooked even for traditionally non-technical analytics roles.\n\n\nTech & Finance Leading Hiring\nOur industry breakdown shows that technology and finance companies are the heaviest recruiters of data science talent. Tech firms are driving innovation through AI products, while finance companies leverage predictive analytics for risk management and investment strategies. These sectors offer strong opportunities, but they also expect candidates to have technical depth combined with business problem-solving skills.\n\n\nAI Gives Analysts an Edge\nBusiness analytics continues to grow across industries, but the professionals who can blend classic analytics with AI-driven insights are positioned for the best opportunities. Companies increasingly value analysts who can not just interpret historical data, but also build predictive models and optimize decisions using machine learning. Upskilling in AI and data science is no longer optional for career advancement in this field.\n\nBack to top ‚Üë\n\n\n\n\n\n\n\n\nReferences\n\nGartner. (2024): ‚ÄúMarketing Budgets: Benchmarks for CMOs in the Era of Less,‚Äùhttps://www.gartner.com/en/marketing/topics/marketing-budget.\n\n\nRichardson, N. (2024): ‚ÄúCIO Interview: Nigel Richardson, European CIO, PepsiCo,‚Äùhttps://www.computerweekly.com/news/366570412/CIO-interview-Nigel-Richardson-European-CIO-PepsiCo.\n\n\nSamuels, M. (2024): ‚ÄúAI‚Äôs Employment Impact: 86% of Workers Fear Job Losses, but Here‚Äôs Some Good News,‚Äùhttps://www.zdnet.com/article/ai-employment-impact-86-of-workers-fear-job-losses-but-heres-some-good-news/.\n\n\nWhite, B. (2024): ‚ÄúThe Future of Work: How AI Is Reshaping Careers,‚Äùhttps://www.harveynash.co.uk/team/bev-white."
  },
  {
    "objectID": "rm_model.html",
    "href": "rm_model.html",
    "title": "Random Forest Classification for ML/Data Science Requirement",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.read_parquet(\"data/eda.parquet\",  engine='pyarrow')\ndf.columns\n\nIndex(['COMPANY', 'LOCATION', 'POSTED', 'MIN_EDULEVELS_NAME',\n       'MAX_EDULEVELS_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE',\n       'TITLE', 'SKILLS', 'SPECIALIZED_SKILLS', 'CERTIFICATIONS',\n       'COMMON_SKILLS', 'SOFTWARE_SKILLS', 'SOC_2021_4_NAME', 'NAICS_2022_6',\n       'NAICS2_NAME', 'REMOTE_TYPE_NAME', 'SALARY', 'TITLE_NAME',\n       'SKILLS_NAME', 'SPECIALIZED_SKILLS_NAME', 'BODY'],\n      dtype='object')\n\n\n\nml_keywords = [\"machine learning\", \"data science\", \"ai\", \"artificial intelligence\", \"deep learning\", \"data scientist\"]\n\ndef requires_ml(skills):\n    if pd.isnull(skills):\n        return 0\n    skills = skills.lower()\n    return int(any(kw in skills for kw in ml_keywords))\n\ndf[\"REQUIRES_ML\"] = df[\"SKILLS_NAME\"].apply(requires_ml)\n\n\nfeatures = [\"TITLE\", \"SOC_2021_4_NAME\", \"NAICS2_NAME\", \"MIN_EDULEVELS_NAME\", \"MIN_YEARS_EXPERIENCE\"]\ntarget = \"REQUIRES_ML\"\n\ndf = df[features + [target, 'BODY']].dropna()\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\ndf_encoded = df.copy()\nlabel_encoders = {}\n\nfor col in features:\n    if df_encoded[col].dtype == \"object\":\n        le = LabelEncoder()\n        df_encoded[col] = le.fit_transform(df_encoded[col])\n        label_encoders[col] = le\n\n\nfrom sklearn.model_selection import train_test_split\n\nX = df_encoded[features]\ny = df_encoded[target]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.76      0.77      0.77      7991\n           1       0.70      0.69      0.70      6278\n\n    accuracy                           0.74     14269\n   macro avg       0.73      0.73      0.73     14269\nweighted avg       0.74      0.74      0.74     14269\n\n\n\n\nimport plotly.express as px\nfig = px.bar(\n    x=rf.feature_importances_,\n    y=features,\n    orientation='h',\n    labels={'x': 'Importance', 'y': 'Feature'},\n    title='Feature Importance ‚Äì ML Role Classification'\n)\n\nfig.update_layout(\n    yaxis=dict(categoryorder='total ascending'),\n    margin=dict(l=100, r=20, t=50, b=20),\n    height=500,\n    template='plotly_white'\n)\n\nfig.write_html(\n    'figures/rm_model_plot1.html',\n    include_plotlyjs='cdn',\n    full_html=False\n)\n\n\n\nThis bar chart displays the feature importance scores from a random forest model predicting whether a job role involves ML/Data Science. The most influential feature by far in the model is the job title (TITLE), which has a significantly higher importance than all other variables. Secondary contributors include industry classification (NAICS2_NAME) and minimum years of experience, where education level and SOC code had relatively low influence on the model‚Äôs prediction. This is suggesting that the job title alone carries strong predictive power for identifying ML-related roles.\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Cleaned job descriptions\ndf['BODY_clean'] = df['BODY'].fillna(\"\").str.lower()\n\n# Target\ny = df['REQUIRES_ML']  # this should be a binary 1/0 column\n\n# TF-IDF vectorization\ntfidf = TfidfVectorizer(max_features=5000, stop_words='english')\nX = tfidf.fit_transform(df['BODY_clean'])\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.82      0.90      0.86     10000\n           1       0.86      0.75      0.80      7836\n\n    accuracy                           0.84     17836\n   macro avg       0.84      0.83      0.83     17836\nweighted avg       0.84      0.84      0.83     17836\n\n\n\n\nimport numpy as np\nimportances = model.feature_importances_\ntop_idx = np.argsort(importances)[-20:]\ntop_words = tfidf.get_feature_names_out()[top_idx]\ntop_importances = importances[top_idx]\n\nfig = px.bar(\n    x=top_importances,\n    y=top_words,\n    orientation='h',\n    labels={'x': 'Importance', 'y': 'Word'},\n    title='Top 20 TF-IDF Words for ML Role Classification'\n)\n\nfig.update_layout(\n    yaxis={'categoryorder':'total ascending'},\n    margin=dict(l=120, r=20, t=60, b=20),\n    width=800, height=600, template='plotly_white'\n)\n\nfig.write_html(\n    'figures/rm_model_plot2.html',\n    include_plotlyjs='cdn',\n    full_html=False\n)\n\n\n\nThis bar chart shows the top words contributing to the classification of job roles as Machine Learning (ML)related based on job description data. Surprisingly, the most influential words are ‚Äúattention,‚Äù ‚Äúchain,‚Äù and ‚Äúsupply‚Äù, which could be an indication of overlap with supply chain roles or reflect noise in the model. More expected terms like ‚Äúmachine,‚Äù ‚Äúlearning,‚Äù ‚Äúpython,‚Äù ‚ÄúAI,‚Äù and ‚Äúanalytics‚Äù also appear, reinforcing that relevant technical language still plays a role in identifying ML-related positions. The presence of general words like ‚Äústrong‚Äù or ‚Äúcommunication‚Äù suggests that not all influential terms are strictly technical.\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport numpy as np\nimport plotly.figure_factory as ff\nlabels = [str(lbl) for lbl in model.classes_]\n\ncm = confusion_matrix(y_test, y_pred)\nlabels = [str(c) for c in model.classes_]  \n\nfig = ff.create_annotated_heatmap(\n    z=cm,\n    x=labels,\n    y=labels,\n    colorscale='Blues',\n    showscale=True,\n    annotation_text=cm,\n    hoverinfo='z'\n)\n\nfig.update_layout(\n    title='Confusion Matrix ‚Äì ML Role Classification',\n    xaxis_title='Predicted Label',\n    yaxis_title='Actual Label',\n    xaxis=dict(tickmode='array', tickvals=list(range(len(labels))), ticktext=labels),\n    yaxis=dict(tickmode='array', tickvals=list(range(len(labels))), ticktext=labels),\n    width=700,\n    height=600,\n    template='plotly_white',\n    margin=dict(l=80, r=20, t=60, b=80)\n)\n\nfig.write_html(\n    \"figures/rm_model_plot3.html\",\n    include_plotlyjs='cdn',\n    full_html=False\n)\n\n\n\nWe selected a combination of structured and unstructured features to predict whether a job role requires Machine Learning or Data Science. Structured features such as TITLE, SOC_2021_4_NAME, NAICS2_NAME, MIN_EDULEVELS_NAME, and MIN_YEARS_EXPERIENCE were chosen based on domain relevance‚Äîthese fields reflect the role‚Äôs function, industry, required education, and experience level, all of which can signal ML-related requirements. Additionally, we included the job description BODY text, applying TF-IDF vectorization to extract key terms. This allowed the model to learn from nuanced language patterns within postings. Feature importance and performance metrics confirm that both structured metadata and text data contribute meaningfully to classification accuracy."
  },
  {
    "objectID": "eda_d.html",
    "href": "eda_d.html",
    "title": "Exploratory Data Analytics",
    "section": "",
    "text": "Code\nimport pandas as pd\neda = pd.read_parquet(\"data/eda.parquet\")\n\n\n\n\nCode\n# identifying data analyst jobs by keyword searching\nkeywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n            'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n            'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n            'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n\nmatch = lambda col: eda[col].str.contains('|'.join(keywords), case=False, na=False)\n\neda['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n             | match('SKILLS_NAME') \\\n             | match('SPECIALIZED_SKILLS_NAME') \neda['DATA_ANALYST_JOB'].value_counts()\n\n\nDATA_ANALYST_JOB\nFalse    38258\nTrue     33083\nName: count, dtype: int64\n\n\n\n\nCode\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\ndf_grouped = (\n    eda\n    .groupby(['DATA_ANALYST_JOB','NAICS2_NAME'])\n    .size()\n    .reset_index(name='Job_Count')\n)\n\nshort_names = {\n    'Professional, Scientific, and Technical Services': 'Prof. Services',\n    'Administrative and Support and Waste Management and Remediation Services': 'Admin & Waste Mgmt',\n    'Health Care and Social Assistance': 'Healthcare',\n    'Finance and Insurance': 'Finance',\n    'Information': 'Info Tech',\n    'Educational Services': 'Education',\n    'Manufacturing': 'Manufacturing',\n    'Retail Trade': 'Retail',\n    'Accommodation and Food Services': 'Hospitality',\n    'Other Services (except Public Administration)': 'Other Services'\n}\ndf_grouped['Industry'] = df_grouped['NAICS2_NAME'].map(short_names).fillna(df_grouped['NAICS2_NAME'])\ndf_grouped['Job_Type'] = df_grouped['DATA_ANALYST_JOB'].map({True:'True', False:'False'})\n\npivot = (\n    df_grouped\n    .pivot_table(index='Industry', columns='Job_Type', values='Job_Count', fill_value=0)\n    .reset_index()\n)\nindustries = pivot['Industry'].tolist()\ny_true  = pivot['True'].tolist()\ny_false = pivot['False'].tolist()\n\n# -----------------------------------------------------------------------------\n# 2) Build a 2-row subplot: bar on top, table below\n# -----------------------------------------------------------------------------\nfig = make_subplots(\n    rows=2, cols=1,\n    row_heights=[0.70, 0.30],           # give a bit more room to the table\n    specs=[[{\"type\":\"bar\"}],[{\"type\":\"table\"}]],\n    vertical_spacing=0.12              # more space between bar and table\n)\n\ncolors = {'True': '#FFE5E5', 'False': '#FF6B6B'}\n\nfig.add_trace(\n    go.Bar(\n        x=industries, y=y_true, name='True',\n        marker=dict(color=colors['True'], line=dict(color='#A81D1D', width=1)),\n        text=y_true, textposition='outside'\n    ),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Bar(\n        x=industries, y=y_false, name='False',\n        marker=dict(color=colors['False'], line=dict(color='#A81D1D', width=1)),\n        text=y_false, textposition='outside'\n    ),\n    row=1, col=1\n)\n\n\n# -----------------------------------------------------------------------------\n# 3) Slider steps: 0 ‚Üí 8 000 in 200s\n# -----------------------------------------------------------------------------\nsteps = []\nfor val in range(0, 8001, 200):\n    steps.append(dict(\n        label=str(val),\n        method=\"update\",\n        args=[\n            {\"y\": [\n                [v if v&gt;=val else 0 for v in y_true],\n                [v if v&gt;=val else 0 for v in y_false]\n            ]},\n            {\"title\": f\"Min Jobs ‚â• {val:,}\"}\n        ]\n    ))\n\n# -----------------------------------------------------------------------------\n# 4) Final layout tweaks\n# -----------------------------------------------------------------------------\nfig.update_layout(\n    # lift slider above everything\n    sliders=[dict(\n        active=0,\n        currentvalue={\"prefix\":\"Min Jobs: \"},\n        pad={\"b\":0},\n        x=0.05,\n        y=1.05,                # move slider way above the plot area\n        xanchor=\"left\",\n        yanchor=\"bottom\",\n        len=0.7,\n        font=dict(color='#A81D1D'),\n        steps=steps\n    )],\n\n    title=dict(\n        text=\"Data & Business Analytics Job Trends\",\n        font=dict(size=24, color='#A81D1D'),\n        x=0.5,\n        y=0.95,                # drop the title just below the slider\n        xanchor=\"center\",\n        yanchor=\"top\"\n    ),\n\n    width=1100, height=850,\n    margin=dict(l=60, r=60, t=180, b=200),  # extra top & bottom margin\n\n    plot_bgcolor='white',\n    paper_bgcolor='white',\n\n    xaxis=dict(\n        title=\"Industry\",\n        title_font=dict(size=16, color='#A81D1D'),\n        tickmode='array',\n        tickvals=list(range(len(industries))),\n        ticktext=industries,\n        tickangle=-30,\n        tickfont=dict(size=11, color='#333'),\n        showline=True, linecolor='#A81D1D'\n    ),\n    yaxis=dict(\n        title=\"Number of Jobs\",\n        title_font=dict(size=16, color='#A81D1D'),\n        tickfont=dict(size=11, color='#333'),\n        gridcolor='rgba(200,200,200,0.3)',\n        showline=True, linecolor='#A81D1D',\n        range=[0, max(max(y_true),max(y_false))*1.2]\n    ),\n\n    legend=dict(\n        title=\"Data Analyst Job\",\n        title_font=dict(color='#A81D1D'),\n        font=dict(size=12),\n        x=0.95, y=0.95\n    ),\n\n    bargap=0.2\n)\n\nfig\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n{python} fig\n\n\n::: {#eecdf826 .cell execution_count=4}\n``` {.python .cell-code}\nimport plotly.express as px\nimport pandas as pd\n\n# Prepare the data\ndf = eda.copy()\n\n# Define analytics jobs (Data Analyst + Business Analyst)\ndef classify_analytics_job(row):\n   if row['DATA_ANALYST_JOB']:\n       return True\n   title = str(row['TITLE_NAME']).lower() if 'TITLE_NAME' in row else str(row['TITLE']).lower()\n   if 'business analyst' in title:\n       return True\n   return False\n\ndf['IS_ANALYTICS_JOB'] = df.apply(classify_analytics_job, axis=1)\ndf['Job_Category'] = df['IS_ANALYTICS_JOB'].map({True: 'Analytics Job', False: 'Non-Analytics Job'})\n\n# Create the box plot\nfig = px.box(df, \n            x='REMOTE_TYPE_NAME', \n            y='SALARY', \n            color='Job_Category',\n            title='Salary Distribution by Remote Type for Analytics vs Non-Analytics Jobs',\n            labels={'REMOTE_TYPE_NAME': 'Remote Type', 'SALARY': 'Salary ($)', 'Job_Category': 'Job Category'},\n            color_discrete_map={'Analytics Job': '#FF6B6B', 'Non-Analytics Job': '#4ECDC4'})\n\n# Beautify the layout with a red-white theme (no gradients)\nfig.update_layout(\n   width=900,\n   height=600,\n   plot_bgcolor='#FFFFFF',  # Plain white background\n   paper_bgcolor='#FFFFFF',  # Plain white background\n   font=dict(family=\"Inter, sans-serif\", size=14, color=\"#2D3748\"),\n   title=dict(\n       font=dict(size=24, color=\"#FF6B6B\"),  # Red title for theme\n       x=0.5,\n       xanchor=\"center\",\n       y=0.95,\n       yanchor=\"top\"\n   ),\n   xaxis=dict(\n       title=\"Remote Type\",\n       title_font=dict(size=16),\n       tickfont=dict(size=12),\n       gridcolor=\"#E2E8F0\",\n       linecolor=\"#2D3748\",\n       linewidth=2,\n       showline=True\n   ),\n   yaxis=dict(\n       title=\"Salary ($)\",\n       title_font=dict(size=16),\n       tickfont=dict(size=12),\n       gridcolor=\"#E2E8F0\",\n       linecolor=\"#2D3748\",\n       linewidth=2,\n       showline=True,\n       showgrid=True,\n       zeroline=False\n   ),\n   legend=dict(\n       title=\"Job Category\",\n       font=dict(size=13),\n       bgcolor=\"#FFFFFF\",\n       bordercolor=\"#FF6B6B\",  # Red border for theme\n       borderwidth=1,\n       x=1.02,\n       y=0.5,\n       xanchor=\"left\",\n       yanchor=\"middle\"\n   ),\n   hovermode=\"closest\",\n   hoverlabel=dict(\n       bgcolor=\"#FFFFFF\",\n       font_size=12,\n       font_family=\"Inter, sans-serif\",\n       font_color=\"#2D3748\",\n       bordercolor=\"#FF6B6B\"  # Red border for hover\n   )\n)\n\nfig\n\n                            \n                                            \n\n:::\n\n{python} fig\n\n\n::: {#0bec075f .cell execution_count=5}\n``` {.python .cell-code}\nimport plotly.express as px\nimport pandas as pd\n\n# Prepare the data\ndf = eda.copy()\n\n# Define analytics jobs (Data Analyst + Business Analyst)\ndef classify_analytics_job(row):\n   if row['DATA_ANALYST_JOB']:\n       return True\n   title = str(row['TITLE_NAME']).lower() if 'TITLE_NAME' in row else str(row['TITLE']).lower()\n   if 'business analyst' in title:\n       return True\n   return False\n\ndf['IS_ANALYTICS_JOB'] = df.apply(classify_analytics_job, axis=1)\ndf['Job_Category'] = df['IS_ANALYTICS_JOB'].map({True: 'Analytics Job', False: 'Non-Analytics Job'})\n\n# Group by industry and job category\ndf_grouped = df.groupby(['NAICS2_NAME', 'IS_ANALYTICS_JOB']).size().reset_index(name='Job_Count')\ndf_grouped['Job_Category'] = df_grouped['IS_ANALYTICS_JOB'].map({True: 'Analytics Job', False: 'Non-Analytics Job'})\n\n# Shorten industry names for better readability\nshort_map = {\n   'Professional, Scientific, and Technical Services': 'Prof. Services',\n   'Administrative and Support and Waste Management and Remediation Services': 'Admin & Waste Mgmt',\n   'Health Care and Social Assistance': 'Healthcare',\n   'Finance and Insurance': 'Finance',\n   'Information': 'Info Tech',\n   'Educational Services': 'Education',\n   'Manufacturing': 'Manufacturing',\n   'Retail Trade': 'Retail',\n   'Accommodation and Food Services': 'Hospitality',\n   'Other Services (except Public Administration)': 'Other Services'\n}\ndf_grouped['Industry'] = df_grouped['NAICS2_NAME'].map(short_map).fillna(df_grouped['NAICS2_NAME'])\n\n# Create the stacked bar chart\nfig = px.bar(df_grouped, \n            x='Industry', \n            y='Job_Count', \n            color='Job_Category',\n            title='Top Industries Hiring Analytics Jobs',\n            labels={'Industry': 'Industry', 'Job_Count': 'Number of Jobs', 'Job_Category': 'Job Category'},\n            barmode='stack',\n            color_discrete_map={'Analytics Job': '#FF6B6B', 'Non-Analytics Job': '#4ECDC4'})\n\n# Beautify the layout with a red-white theme (no gradients)\nfig.update_layout(\n   width=1000,\n   height=600,\n   plot_bgcolor='#FFFFFF',  # Plain white background\n   paper_bgcolor='#FFFFFF',  # Plain white background\n   font=dict(family=\"Inter, sans-serif\", size=14, color=\"#2D3748\"),\n   title=dict(\n       font=dict(size=24, color=\"#FF6B6B\"),  # Red title for theme\n       x=0.5,\n       xanchor=\"center\",\n       y=0.95,\n       yanchor=\"top\"\n   ),\n   xaxis=dict(\n       title=\"Industry\",\n       title_font=dict(size=16),\n       tickfont=dict(size=12),\n       tickangle=-45,\n       gridcolor=\"#E2E8F0\",\n       linecolor=\"#2D3748\",\n       linewidth=2,\n       showline=True\n   ),\n   yaxis=dict(\n       title=\"Number of Jobs\",\n       title_font=dict(size=16),\n       tickfont=dict(size=12),\n       gridcolor=\"#E2E8F0\",\n       linecolor=\"#2D3748\",\n       linewidth=2,\n       showline=True,\n       showgrid=True,\n       zeroline=False\n   ),\n   legend=dict(\n       title=\"Job Category\",\n       font=dict(size=13),\n       bgcolor=\"#FFFFFF\",\n       bordercolor=\"#FF6B6B\",  # Red border for theme\n       borderwidth=1,\n       x=1.02,\n       y=0.5,\n       xanchor=\"left\",\n       yanchor=\"middle\"\n   ),\n   hovermode=\"closest\",\n   hoverlabel=dict(\n       bgcolor=\"#FFFFFF\",\n       font_size=12,\n       font_family=\"Inter, sans-serif\",\n       font_color=\"#2D3748\",\n       bordercolor=\"#FF6B6B\"  # Red border for hover\n   )\n)\nfig\n\n                            \n                                            \n\n:::\n\n{python} fig\n\n\n::: {#c724fe94 .cell execution_count=6}\n``` {.python .cell-code}\nimport plotly.express as px\nimport pandas as pd\n\n# Prepare the data\ndf = eda.copy()\n\n# Define analytics jobs (Data Analyst + Business Analyst)\ndef classify_analytics_job(row):\n   if row['DATA_ANALYST_JOB']:\n       return True\n   title = str(row['TITLE_NAME']).lower() if 'TITLE_NAME' in row else str(row['TITLE']).lower()\n   if 'business analyst' in title:\n       return True\n   return False\n\ndf['IS_ANALYTICS_JOB'] = df.apply(classify_analytics_job, axis=1)\ndf['Job_Category'] = df['IS_ANALYTICS_JOB'].map({True: 'Analytics Job', False: 'Non-Analytics Job'})\n\n# Calculate average years of experience\ndf['Avg_Years_Experience'] = (df['MIN_YEARS_EXPERIENCE'] + df['MAX_YEARS_EXPERIENCE']) / 2\n\n# Clean the data (remove rows with missing salary or experience)\ndf = df.dropna(subset=['Avg_Years_Experience', 'SALARY'])\n\n# Create the scatter plot with trend line\nfig = px.scatter(df, \n                x='Avg_Years_Experience', \n                y='SALARY', \n                color='Job_Category',\n                trendline='ols',  # Add trend line (ordinary least squares)\n                title='Experience Requirements vs Salary for Analytics Jobs',\n                labels={'Avg_Years_Experience': 'Average Years of Experience', 'SALARY': 'Salary ($)', 'Job_Category': 'Job Category'},\n                color_discrete_map={'Analytics Job': '#FF6B6B', 'Non-Analytics Job': '#4ECDC4'})\n\n# Beautify the layout with a red-white theme (no gradients)\nfig.update_layout(\n   width=900,\n   height=600,\n   plot_bgcolor='#FFFFFF',  # Plain white background\n   paper_bgcolor='#FFFFFF',  # Plain white background\n   font=dict(family=\"Inter, sans-serif\", size=14, color=\"#2D3748\"),\n   title=dict(\n       font=dict(size=24, color=\"#FF6B6B\"),  # Red title for theme\n       x=0.5,\n       xanchor=\"center\",\n       y=0.95,\n       yanchor=\"top\"\n   ),\n   xaxis=dict(\n       title=\"Average Years of Experience\",\n       title_font=dict(size=16),\n       tickfont=dict(size=12),\n       gridcolor=\"#E2E8F0\",\n       linecolor=\"#2D3748\",\n       linewidth=2,\n       showline=True,\n       showgrid=True,\n       zeroline=False\n   ),\n   yaxis=dict(\n       title=\"Salary ($)\",\n       title_font=dict(size=16),\n       tickfont=dict(size=12),\n       gridcolor=\"#E2E8F0\",\n       linecolor=\"#2D3748\",\n       linewidth=2,\n       showline=True,\n       showgrid=True,\n       zeroline=False\n   ),\n   legend=dict(\n       title=\"Job Category\",\n       font=dict(size=13),\n       bgcolor=\"#FFFFFF\",\n       bordercolor=\"#FF6B6B\",  # Red border for theme\n       borderwidth=1,\n       x=1.02,\n       y=0.5,\n       xanchor=\"left\",\n       yanchor=\"middle\"\n   ),\n   hovermode=\"closest\",\n   hoverlabel=dict(\n       bgcolor=\"#FFFFFF\",\n       font_size=12,\n       font_family=\"Inter, sans-serif\",\n       font_color=\"#2D3748\",\n       bordercolor=\"#FF6B6B\"  # Red border for hover\n   )\n)\n\n# Customize scatter points\nfig.update_traces(\n   marker=dict(\n       size=8,\n       opacity=0.7,\n       line=dict(width=1, color=\"#2D3748\")\n   )\n)\nfig\n\n                            \n                                            \n\n:::\n\n{python} fig\n\n\n::: {#fc82a6a3 .cell execution_count=7}\n``` {.python .cell-code}\nimport plotly.graph_objects as go\nimport pandas as pd\n\n# Prepare the data\ndf = eda.copy()\n\n# Define analytics jobs (Data Analyst + Business Analyst)\ndef classify_analytics_job(row):\n   if row['DATA_ANALYST_JOB']:\n       return True\n   title = str(row['TITLE_NAME']).lower() if 'TITLE_NAME' in row else str(row['TITLE']).lower()\n   if 'business analyst' in title:\n       return True\n   return False\n\ndf['IS_ANALYTICS_JOB'] = df.apply(classify_analytics_job, axis=1)\ndf['Job_Category'] = df['IS_ANALYTICS_JOB'].map({True: 'Analytics Job', False: 'Non-Analytics Job'})\n\n# Filter for Analytics jobs only\ndf_analytics = df[df['IS_ANALYTICS_JOB']].copy()\n\n# Clean the data (remove rows with missing industry)\ndf_analytics = df_analytics.dropna(subset=['NAICS2_NAME'])\n\n# Group by job category and industry to get job counts\ndf_grouped = df_analytics.groupby(['Job_Category', 'NAICS2_NAME']).size().reset_index(name='Job_Count')\n\n# Shorten industry names for better readability\nshort_map = {\n   'Professional, Scientific, and Technical Services': 'Prof. Services',\n   'Administrative and Support and Waste Management and Remediation Services': 'Admin & Waste Mgmt',\n   'Health Care and Social Assistance': 'Healthcare',\n   'Finance and Insurance': 'Finance',\n   'Information': 'Info Tech',\n   'Educational Services': 'Education',\n   'Manufacturing': 'Manufacturing',\n   'Retail Trade': 'Retail',\n   'Accommodation and Food Services': 'Hospitality',\n   'Other Services (except Public Administration)': 'Other Services'\n}\ndf_grouped['NAICS2_NAME'] = df_grouped['NAICS2_NAME'].map(short_map).fillna(df_grouped['NAICS2_NAME'])\n\n# Prepare data for Sankey Diagram\n# Create a list of unique labels (nodes)\nlabels = list(df_grouped['Job_Category'].unique()) + list(df_grouped['NAICS2_NAME'].unique())\n\n# Create source and target indices\nsource = [labels.index(job_cat) for job_cat in df_grouped['Job_Category']]\ntarget = [labels.index(industry) for industry in df_grouped['NAICS2_NAME']]\nvalue = df_grouped['Job_Count'].tolist()\n\n# Create the Sankey Diagram\nfig = go.Figure(data=[go.Sankey(\n   node=dict(\n       pad=15,\n       thickness=20,\n       line=dict(color=\"#2D3748\", width=0.5),\n       label=labels,\n       color=\"#FF6B6B\"  # Red nodes for the theme\n   ),\n   link=dict(\n       source=source,\n       target=target,\n       value=value,\n       color=\"rgba(255, 107, 107, 0.5)\"  # Semi-transparent red links\n   )\n)])\n\n# Beautify the layout with a red-white theme (no gradients)\nfig.update_layout(\n   width=900,\n   height=600,\n   plot_bgcolor='#FFFFFF',  # Plain white background\n   paper_bgcolor='#FFFFFF',  # Plain white background\n   font=dict(family=\"Inter, sans-serif\", size=14, color=\"#2D3748\"),\n   title=dict(\n       text='Distribution of Analytics Job Postings by Industry',\n       font=dict(size=24, color=\"#FF6B6B\"),  # Red title for theme\n       x=0.5,\n       xanchor=\"center\",\n       y=0.95,\n       yanchor=\"top\"\n   ),\n   margin=dict(l=20, r=20, t=80, b=20),\n)\nfig\n\n                            \n                                            \n\n:::\n\n{python} fig\n\n```"
  }
]