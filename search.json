[
  {
    "objectID": "eda_d.html",
    "href": "eda_d.html",
    "title": "Exploratory Data Analytics",
    "section": "",
    "text": "Code\nimport pandas as pd\n\n# one-time conversion on your machine\neda = pd.read_csv(\"data/eda_data.csv\")\neda.to_parquet(\"data/eda.parquet\", index=False)\neda = pd.read_parquet(\"data/eda.parquet\")\n\n\n\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[1], line 4\n      1 import pandas as pd\n      3 # one-time conversion on your machine\n----&gt; 4 eda = pd.read_csv(\"data/eda_data.csv\")\n      5 eda.to_parquet(\"data/eda.parquet\", index=False)\n      6 eda = pd.read_parquet(\"data/eda.parquet\")\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: 'data/eda_data.csv'\n\n\n\n\n\nCode\n# identifying data analyst jobs by keyword searching\nkeywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n            'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n            'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n            'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n\nmatch = lambda col: eda[col].str.contains('|'.join(keywords), case=False, na=False)\n\neda['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n             | match('SKILLS_NAME') \\\n             | match('SPECIALIZED_SKILLS_NAME') \neda['DATA_ANALYST_JOB'].value_counts()\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[2], line 9\n      2 keywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n      3             'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n      4             'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n      5             'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n      7 match = lambda col: eda[col].str.contains('|'.join(keywords), case=False, na=False)\n----&gt; 9 eda['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n     10              | match('SKILLS_NAME') \\\n     11              | match('SPECIALIZED_SKILLS_NAME') \n     12 eda['DATA_ANALYST_JOB'].value_counts()\n\nCell In[2], line 7, in &lt;lambda&gt;(col)\n      1 # identifying data analyst jobs by keyword searching\n      2 keywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n      3             'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n      4             'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n      5             'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n----&gt; 7 match = lambda col: eda[col].str.contains('|'.join(keywords), case=False, na=False)\n      9 eda['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n     10              | match('SKILLS_NAME') \\\n     11              | match('SPECIALIZED_SKILLS_NAME') \n     12 eda['DATA_ANALYST_JOB'].value_counts()\n\nNameError: name 'eda' is not defined\n\n\n\n\n\nCode\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\ndf_grouped = (\n    eda\n    .groupby(['DATA_ANALYST_JOB','NAICS2_NAME'])\n    .size()\n    .reset_index(name='Job_Count')\n)\n\nshort_names = {\n    'Professional, Scientific, and Technical Services': 'Prof. Services',\n    'Administrative and Support and Waste Management and Remediation Services': 'Admin & Waste Mgmt',\n    'Health Care and Social Assistance': 'Healthcare',\n    'Finance and Insurance': 'Finance',\n    'Information': 'Info Tech',\n    'Educational Services': 'Education',\n    'Manufacturing': 'Manufacturing',\n    'Retail Trade': 'Retail',\n    'Accommodation and Food Services': 'Hospitality',\n    'Other Services (except Public Administration)': 'Other Services'\n}\ndf_grouped['Industry'] = df_grouped['NAICS2_NAME'].map(short_names).fillna(df_grouped['NAICS2_NAME'])\ndf_grouped['Job_Type'] = df_grouped['DATA_ANALYST_JOB'].map({True:'True', False:'False'})\n\npivot = (\n    df_grouped\n    .pivot_table(index='Industry', columns='Job_Type', values='Job_Count', fill_value=0)\n    .reset_index()\n)\nindustries = pivot['Industry'].tolist()\ny_true  = pivot['True'].tolist()\ny_false = pivot['False'].tolist()\n\n# -----------------------------------------------------------------------------\n# 2) Build a 2-row subplot: bar on top, table below\n# -----------------------------------------------------------------------------\nfig = make_subplots(\n    rows=2, cols=1,\n    row_heights=[0.70, 0.30],           # give a bit more room to the table\n    specs=[[{\"type\":\"bar\"}],[{\"type\":\"table\"}]],\n    vertical_spacing=0.12              # more space between bar and table\n)\n\ncolors = {'True': '#FFE5E5', 'False': '#FF6B6B'}\n\nfig.add_trace(\n    go.Bar(\n        x=industries, y=y_true, name='True',\n        marker=dict(color=colors['True'], line=dict(color='#A81D1D', width=1)),\n        text=y_true, textposition='outside'\n    ),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Bar(\n        x=industries, y=y_false, name='False',\n        marker=dict(color=colors['False'], line=dict(color='#A81D1D', width=1)),\n        text=y_false, textposition='outside'\n    ),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Table(\n        header=dict(\n            values=[\"Industry\",\"True\",\"False\"],\n            fill_color='#FDEDEC',\n            align='left',\n            font=dict(color='#A81D1D', size=13),\n            height=30\n        ),\n        cells=dict(\n            values=[industries, y_true, y_false],\n            fill_color='white',\n            align='left',\n            font=dict(color='#333', size=11),\n            height=22\n        )\n    ),\n    row=2, col=1\n)\n\n# -----------------------------------------------------------------------------\n# 3) Slider steps: 0 → 8 000 in 200s\n# -----------------------------------------------------------------------------\nsteps = []\nfor val in range(0, 8001, 200):\n    steps.append(dict(\n        label=str(val),\n        method=\"update\",\n        args=[\n            {\"y\": [\n                [v if v&gt;=val else 0 for v in y_true],\n                [v if v&gt;=val else 0 for v in y_false]\n            ]},\n            {\"title\": f\"Min Jobs ≥ {val:,}\"}\n        ]\n    ))\n\n# -----------------------------------------------------------------------------\n# 4) Final layout tweaks\n# -----------------------------------------------------------------------------\nfig.update_layout(\n    # lift slider above everything\n    sliders=[dict(\n        active=0,\n        currentvalue={\"prefix\":\"Min Jobs: \"},\n        pad={\"b\":0},\n        x=0.15,\n        y=1.18,                # move slider way above the plot area\n        xanchor=\"left\",\n        yanchor=\"bottom\",\n        len=0.7,\n        font=dict(color='#A81D1D'),\n        steps=steps\n    )],\n\n    title=dict(\n        text=\"Data & Business Analytics Job Trends\",\n        font=dict(size=24, color='#A81D1D'),\n        x=0.5,\n        y=0.92,                # drop the title just below the slider\n        xanchor=\"center\",\n        yanchor=\"top\"\n    ),\n\n    width=1100, height=850,\n    margin=dict(l=60, r=60, t=180, b=200),  # extra top & bottom margin\n\n    plot_bgcolor='white',\n    paper_bgcolor='white',\n\n    xaxis=dict(\n        title=\"Industry\",\n        title_font=dict(size=16, color='#A81D1D'),\n        tickmode='array',\n        tickvals=list(range(len(industries))),\n        ticktext=industries,\n        tickangle=-30,\n        tickfont=dict(size=11, color='#333'),\n        showline=True, linecolor='#A81D1D'\n    ),\n    yaxis=dict(\n        title=\"Number of Jobs\",\n        title_font=dict(size=16, color='#A81D1D'),\n        tickfont=dict(size=11, color='#333'),\n        gridcolor='rgba(200,200,200,0.3)',\n        showline=True, linecolor='#A81D1D',\n        range=[0, max(max(y_true),max(y_false))*1.2]\n    ),\n\n    legend=dict(\n        title=\"Data Analyst Job\",\n        title_font=dict(color='#A81D1D'),\n        font=dict(size=12),\n        x=1.02, y=0.5\n    ),\n\n    bargap=0.2\n)\nfig.write_html(\n    \"figures/edaplot1.html\",\n    include_plotlyjs=\"cdn\",  \n    full_html=False    \n)\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 6\n      2 import plotly.graph_objects as go\n      3 from plotly.subplots import make_subplots\n      5 df_grouped = (\n----&gt; 6     eda\n      7     .groupby(['DATA_ANALYST_JOB','NAICS2_NAME'])\n      8     .size()\n      9     .reset_index(name='Job_Count')\n     10 )\n     12 short_names = {\n     13     'Professional, Scientific, and Technical Services': 'Prof. Services',\n     14     'Administrative and Support and Waste Management and Remediation Services': 'Admin & Waste Mgmt',\n   (...)\n     22     'Other Services (except Public Administration)': 'Other Services'\n     23 }\n     24 df_grouped['Industry'] = df_grouped['NAICS2_NAME'].map(short_names).fillna(df_grouped['NAICS2_NAME'])\n\nNameError: name 'eda' is not defined\n\n\n\n\n\n\n\nCode\nimport plotly.express as px\nimport pandas as pd\n\n# Prepare the data\ndf = eda.copy()\n\n# Define analytics jobs (Data Analyst + Business Analyst)\ndef classify_analytics_job(row):\n    if row['DATA_ANALYST_JOB']:\n        return True\n    title = str(row['TITLE_NAME']).lower() if 'TITLE_NAME' in row else str(row['TITLE']).lower()\n    if 'business analyst' in title:\n        return True\n    return False\n\ndf['IS_ANALYTICS_JOB'] = df.apply(classify_analytics_job, axis=1)\ndf['Job_Category'] = df['IS_ANALYTICS_JOB'].map({True: 'Analytics Job', False: 'Non-Analytics Job'})\n\n# Create the box plot\nfig = px.box(df, \n             x='REMOTE_TYPE_NAME', \n             y='SALARY', \n             color='Job_Category',\n             title='Salary Distribution by Remote Type for Analytics vs Non-Analytics Jobs',\n             labels={'REMOTE_TYPE_NAME': 'Remote Type', 'SALARY': 'Salary ($)', 'Job_Category': 'Job Category'},\n             color_discrete_map={'Analytics Job': '#FF6B6B', 'Non-Analytics Job': '#4ECDC4'})\n\n# Beautify the layout with a red-white theme (no gradients)\nfig.update_layout(\n    width=900,\n    height=600,\n    plot_bgcolor='#FFFFFF',  # Plain white background\n    paper_bgcolor='#FFFFFF',  # Plain white background\n    font=dict(family=\"Inter, sans-serif\", size=14, color=\"#2D3748\"),\n    title=dict(\n        font=dict(size=24, color=\"#FF6B6B\"),  # Red title for theme\n        x=0.5,\n        xanchor=\"center\",\n        y=0.95,\n        yanchor=\"top\"\n    ),\n    xaxis=dict(\n        title=\"Remote Type\",\n        title_font=dict(size=16),\n        tickfont=dict(size=12),\n        gridcolor=\"#E2E8F0\",\n        linecolor=\"#2D3748\",\n        linewidth=2,\n        showline=True\n    ),\n    yaxis=dict(\n        title=\"Salary ($)\",\n        title_font=dict(size=16),\n        tickfont=dict(size=12),\n        gridcolor=\"#E2E8F0\",\n        linecolor=\"#2D3748\",\n        linewidth=2,\n        showline=True,\n        showgrid=True,\n        zeroline=False\n    ),\n    legend=dict(\n        title=\"Job Category\",\n        font=dict(size=13),\n        bgcolor=\"#FFFFFF\",\n        bordercolor=\"#FF6B6B\",  # Red border for theme\n        borderwidth=1,\n        x=1.02,\n        y=0.5,\n        xanchor=\"left\",\n        yanchor=\"middle\"\n    ),\n    hovermode=\"closest\",\n    hoverlabel=dict(\n        bgcolor=\"#FFFFFF\",\n        font_size=12,\n        font_family=\"Inter, sans-serif\",\n        font_color=\"#2D3748\",\n        bordercolor=\"#FF6B6B\"  # Red border for hover\n    )\n)\n\nfig.write_html(\n    \"figures/edaplot2.html\",\n    include_plotlyjs=\"cdn\",  \n    full_html=False    \n)\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[4], line 5\n      2 import pandas as pd\n      4 # Prepare the data\n----&gt; 5 df = eda.copy()\n      7 # Define analytics jobs (Data Analyst + Business Analyst)\n      8 def classify_analytics_job(row):\n\nNameError: name 'eda' is not defined\n\n\n\n\n\n\n\nCode\nimport plotly.express as px\nimport pandas as pd\n\n# Prepare the data\ndf = eda.copy()\n\n# Define analytics jobs (Data Analyst + Business Analyst)\ndef classify_analytics_job(row):\n    if row['DATA_ANALYST_JOB']:\n        return True\n    title = str(row['TITLE_NAME']).lower() if 'TITLE_NAME' in row else str(row['TITLE']).lower()\n    if 'business analyst' in title:\n        return True\n    return False\n\ndf['IS_ANALYTICS_JOB'] = df.apply(classify_analytics_job, axis=1)\ndf['Job_Category'] = df['IS_ANALYTICS_JOB'].map({True: 'Analytics Job', False: 'Non-Analytics Job'})\n\n# Group by industry and job category\ndf_grouped = df.groupby(['NAICS2_NAME', 'IS_ANALYTICS_JOB']).size().reset_index(name='Job_Count')\ndf_grouped['Job_Category'] = df_grouped['IS_ANALYTICS_JOB'].map({True: 'Analytics Job', False: 'Non-Analytics Job'})\n\n# Shorten industry names for better readability\nshort_map = {\n    'Professional, Scientific, and Technical Services': 'Prof. Services',\n    'Administrative and Support and Waste Management and Remediation Services': 'Admin & Waste Mgmt',\n    'Health Care and Social Assistance': 'Healthcare',\n    'Finance and Insurance': 'Finance',\n    'Information': 'Info Tech',\n    'Educational Services': 'Education',\n    'Manufacturing': 'Manufacturing',\n    'Retail Trade': 'Retail',\n    'Accommodation and Food Services': 'Hospitality',\n    'Other Services (except Public Administration)': 'Other Services'\n}\ndf_grouped['Industry'] = df_grouped['NAICS2_NAME'].map(short_map).fillna(df_grouped['NAICS2_NAME'])\n\n# Create the stacked bar chart\nfig = px.bar(df_grouped, \n             x='Industry', \n             y='Job_Count', \n             color='Job_Category',\n             title='Top Industries Hiring Analytics Jobs',\n             labels={'Industry': 'Industry', 'Job_Count': 'Number of Jobs', 'Job_Category': 'Job Category'},\n             barmode='stack',\n             color_discrete_map={'Analytics Job': '#FF6B6B', 'Non-Analytics Job': '#4ECDC4'})\n\n# Beautify the layout with a red-white theme (no gradients)\nfig.update_layout(\n    width=1000,\n    height=600,\n    plot_bgcolor='#FFFFFF',  # Plain white background\n    paper_bgcolor='#FFFFFF',  # Plain white background\n    font=dict(family=\"Inter, sans-serif\", size=14, color=\"#2D3748\"),\n    title=dict(\n        font=dict(size=24, color=\"#FF6B6B\"),  # Red title for theme\n        x=0.5,\n        xanchor=\"center\",\n        y=0.95,\n        yanchor=\"top\"\n    ),\n    xaxis=dict(\n        title=\"Industry\",\n        title_font=dict(size=16),\n        tickfont=dict(size=12),\n        tickangle=-45,\n        gridcolor=\"#E2E8F0\",\n        linecolor=\"#2D3748\",\n        linewidth=2,\n        showline=True\n    ),\n    yaxis=dict(\n        title=\"Number of Jobs\",\n        title_font=dict(size=16),\n        tickfont=dict(size=12),\n        gridcolor=\"#E2E8F0\",\n        linecolor=\"#2D3748\",\n        linewidth=2,\n        showline=True,\n        showgrid=True,\n        zeroline=False\n    ),\n    legend=dict(\n        title=\"Job Category\",\n        font=dict(size=13),\n        bgcolor=\"#FFFFFF\",\n        bordercolor=\"#FF6B6B\",  # Red border for theme\n        borderwidth=1,\n        x=1.02,\n        y=0.5,\n        xanchor=\"left\",\n        yanchor=\"middle\"\n    ),\n    hovermode=\"closest\",\n    hoverlabel=dict(\n        bgcolor=\"#FFFFFF\",\n        font_size=12,\n        font_family=\"Inter, sans-serif\",\n        font_color=\"#2D3748\",\n        bordercolor=\"#FF6B6B\"  # Red border for hover\n    )\n)\nfig.write_html(\n    \"figures/edaplot3.html\",\n    include_plotlyjs=\"cdn\",  \n    full_html=False    \n)\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[5], line 5\n      2 import pandas as pd\n      4 # Prepare the data\n----&gt; 5 df = eda.copy()\n      7 # Define analytics jobs (Data Analyst + Business Analyst)\n      8 def classify_analytics_job(row):\n\nNameError: name 'eda' is not defined\n\n\n\n\n\n\n\nCode\nimport plotly.express as px\nimport pandas as pd\n\n# Prepare the data\ndf = eda.copy()\n\n# Define analytics jobs (Data Analyst + Business Analyst)\ndef classify_analytics_job(row):\n    if row['DATA_ANALYST_JOB']:\n        return True\n    title = str(row['TITLE_NAME']).lower() if 'TITLE_NAME' in row else str(row['TITLE']).lower()\n    if 'business analyst' in title:\n        return True\n    return False\n\ndf['IS_ANALYTICS_JOB'] = df.apply(classify_analytics_job, axis=1)\ndf['Job_Category'] = df['IS_ANALYTICS_JOB'].map({True: 'Analytics Job', False: 'Non-Analytics Job'})\n\n# Calculate average years of experience\ndf['Avg_Years_Experience'] = (df['MIN_YEARS_EXPERIENCE'] + df['MAX_YEARS_EXPERIENCE']) / 2\n\n# Clean the data (remove rows with missing salary or experience)\ndf = df.dropna(subset=['Avg_Years_Experience', 'SALARY'])\n\n# Create the scatter plot with trend line\nfig = px.scatter(df, \n                 x='Avg_Years_Experience', \n                 y='SALARY', \n                 color='Job_Category',\n                 trendline='ols',  # Add trend line (ordinary least squares)\n                 title='Experience Requirements vs Salary for Analytics Jobs',\n                 labels={'Avg_Years_Experience': 'Average Years of Experience', 'SALARY': 'Salary ($)', 'Job_Category': 'Job Category'},\n                 color_discrete_map={'Analytics Job': '#FF6B6B', 'Non-Analytics Job': '#4ECDC4'})\n\n# Beautify the layout with a red-white theme (no gradients)\nfig.update_layout(\n    width=900,\n    height=600,\n    plot_bgcolor='#FFFFFF',  # Plain white background\n    paper_bgcolor='#FFFFFF',  # Plain white background\n    font=dict(family=\"Inter, sans-serif\", size=14, color=\"#2D3748\"),\n    title=dict(\n        font=dict(size=24, color=\"#FF6B6B\"),  # Red title for theme\n        x=0.5,\n        xanchor=\"center\",\n        y=0.95,\n        yanchor=\"top\"\n    ),\n    xaxis=dict(\n        title=\"Average Years of Experience\",\n        title_font=dict(size=16),\n        tickfont=dict(size=12),\n        gridcolor=\"#E2E8F0\",\n        linecolor=\"#2D3748\",\n        linewidth=2,\n        showline=True,\n        showgrid=True,\n        zeroline=False\n    ),\n    yaxis=dict(\n        title=\"Salary ($)\",\n        title_font=dict(size=16),\n        tickfont=dict(size=12),\n        gridcolor=\"#E2E8F0\",\n        linecolor=\"#2D3748\",\n        linewidth=2,\n        showline=True,\n        showgrid=True,\n        zeroline=False\n    ),\n    legend=dict(\n        title=\"Job Category\",\n        font=dict(size=13),\n        bgcolor=\"#FFFFFF\",\n        bordercolor=\"#FF6B6B\",  # Red border for theme\n        borderwidth=1,\n        x=1.02,\n        y=0.5,\n        xanchor=\"left\",\n        yanchor=\"middle\"\n    ),\n    hovermode=\"closest\",\n    hoverlabel=dict(\n        bgcolor=\"#FFFFFF\",\n        font_size=12,\n        font_family=\"Inter, sans-serif\",\n        font_color=\"#2D3748\",\n        bordercolor=\"#FF6B6B\"  # Red border for hover\n    )\n)\n\n# Customize scatter points\nfig.update_traces(\n    marker=dict(\n        size=8,\n        opacity=0.7,\n        line=dict(width=1, color=\"#2D3748\")\n    )\n)\nfig.write_html(\n    \"figures/edaplot4.html\",\n    include_plotlyjs=\"cdn\",  \n    full_html=False    \n)\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[6], line 5\n      2 import pandas as pd\n      4 # Prepare the data\n----&gt; 5 df = eda.copy()\n      7 # Define analytics jobs (Data Analyst + Business Analyst)\n      8 def classify_analytics_job(row):\n\nNameError: name 'eda' is not defined\n\n\n\n\n\n\n\nCode\nimport plotly.graph_objects as go\nimport pandas as pd\n\n# Prepare the data\ndf = eda.copy()\n\n# Define analytics jobs (Data Analyst + Business Analyst)\ndef classify_analytics_job(row):\n    if row['DATA_ANALYST_JOB']:\n        return True\n    title = str(row['TITLE_NAME']).lower() if 'TITLE_NAME' in row else str(row['TITLE']).lower()\n    if 'business analyst' in title:\n        return True\n    return False\n\ndf['IS_ANALYTICS_JOB'] = df.apply(classify_analytics_job, axis=1)\ndf['Job_Category'] = df['IS_ANALYTICS_JOB'].map({True: 'Analytics Job', False: 'Non-Analytics Job'})\n\n# Filter for Analytics jobs only\ndf_analytics = df[df['IS_ANALYTICS_JOB']].copy()\n\n# Clean the data (remove rows with missing industry)\ndf_analytics = df_analytics.dropna(subset=['NAICS2_NAME'])\n\n# Group by job category and industry to get job counts\ndf_grouped = df_analytics.groupby(['Job_Category', 'NAICS2_NAME']).size().reset_index(name='Job_Count')\n\n# Shorten industry names for better readability\nshort_map = {\n    'Professional, Scientific, and Technical Services': 'Prof. Services',\n    'Administrative and Support and Waste Management and Remediation Services': 'Admin & Waste Mgmt',\n    'Health Care and Social Assistance': 'Healthcare',\n    'Finance and Insurance': 'Finance',\n    'Information': 'Info Tech',\n    'Educational Services': 'Education',\n    'Manufacturing': 'Manufacturing',\n    'Retail Trade': 'Retail',\n    'Accommodation and Food Services': 'Hospitality',\n    'Other Services (except Public Administration)': 'Other Services'\n}\ndf_grouped['NAICS2_NAME'] = df_grouped['NAICS2_NAME'].map(short_map).fillna(df_grouped['NAICS2_NAME'])\n\n# Prepare data for Sankey Diagram\n# Create a list of unique labels (nodes)\nlabels = list(df_grouped['Job_Category'].unique()) + list(df_grouped['NAICS2_NAME'].unique())\n\n# Create source and target indices\nsource = [labels.index(job_cat) for job_cat in df_grouped['Job_Category']]\ntarget = [labels.index(industry) for industry in df_grouped['NAICS2_NAME']]\nvalue = df_grouped['Job_Count'].tolist()\n\n# Create the Sankey Diagram\nfig = go.Figure(data=[go.Sankey(\n    node=dict(\n        pad=15,\n        thickness=20,\n        line=dict(color=\"#2D3748\", width=0.5),\n        label=labels,\n        color=\"#FF6B6B\"  # Red nodes for the theme\n    ),\n    link=dict(\n        source=source,\n        target=target,\n        value=value,\n        color=\"rgba(255, 107, 107, 0.5)\"  # Semi-transparent red links\n    )\n)])\n\n# Beautify the layout with a red-white theme (no gradients)\nfig.update_layout(\n    width=900,\n    height=600,\n    plot_bgcolor='#FFFFFF',  # Plain white background\n    paper_bgcolor='#FFFFFF',  # Plain white background\n    font=dict(family=\"Inter, sans-serif\", size=14, color=\"#2D3748\"),\n    title=dict(\n        text='Distribution of Analytics Job Postings by Industry',\n        font=dict(size=24, color=\"#FF6B6B\"),  # Red title for theme\n        x=0.5,\n        xanchor=\"center\",\n        y=0.95,\n        yanchor=\"top\"\n    ),\n    margin=dict(l=20, r=20, t=80, b=20),\n)\nfig.write_html(\n    \"figures/edaplot5.html\",\n    include_plotlyjs=\"cdn\",  \n    full_html=False    \n)\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 5\n      2 import pandas as pd\n      4 # Prepare the data\n----&gt; 5 df = eda.copy()\n      7 # Define analytics jobs (Data Analyst + Business Analyst)\n      8 def classify_analytics_job(row):\n\nNameError: name 'eda' is not defined"
  },
  {
    "objectID": "rm_model.html",
    "href": "rm_model.html",
    "title": "Random Forest Classification for ML/Data Science Requirement",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\ndf.columns\n\n\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[1], line 3\n      1 import pandas as pd\n----&gt; 3 df = pd.read_csv(\"data/lightcast_job_postings.csv\")\n      4 df.columns\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: 'data/lightcast_job_postings.csv'\n\n\n\n\nml_keywords = [\"machine learning\", \"data science\", \"ai\", \"artificial intelligence\", \"deep learning\", \"data scientist\"]\n\ndef requires_ml(skills):\n    if pd.isnull(skills):\n        return 0\n    skills = skills.lower()\n    return int(any(kw in skills for kw in ml_keywords))\n\ndf[\"REQUIRES_ML\"] = df[\"SKILLS_NAME\"].apply(requires_ml)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[2], line 9\n      6     skills = skills.lower()\n      7     return int(any(kw in skills for kw in ml_keywords))\n----&gt; 9 df[\"REQUIRES_ML\"] = df[\"SKILLS_NAME\"].apply(requires_ml)\n\nNameError: name 'df' is not defined\n\n\n\n\nfeatures = [\"TITLE\", \"SOC_2021_4_NAME\", \"NAICS2_NAME\", \"MIN_EDULEVELS_NAME\", \"MIN_YEARS_EXPERIENCE\"]\ntarget = \"REQUIRES_ML\"\n\ndf = df[features + [target, 'BODY']].dropna()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 4\n      1 features = [\"TITLE\", \"SOC_2021_4_NAME\", \"NAICS2_NAME\", \"MIN_EDULEVELS_NAME\", \"MIN_YEARS_EXPERIENCE\"]\n      2 target = \"REQUIRES_ML\"\n----&gt; 4 df = df[features + [target, 'BODY']].dropna()\n\nNameError: name 'df' is not defined\n\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\ndf_encoded = df.copy()\nlabel_encoders = {}\n\nfor col in features:\n    if df_encoded[col].dtype == \"object\":\n        le = LabelEncoder()\n        df_encoded[col] = le.fit_transform(df_encoded[col])\n        label_encoders[col] = le\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[4], line 3\n      1 from sklearn.preprocessing import LabelEncoder\n----&gt; 3 df_encoded = df.copy()\n      4 label_encoders = {}\n      6 for col in features:\n\nNameError: name 'df' is not defined\n\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nX = df_encoded[features]\ny = df_encoded[target]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[5], line 3\n      1 from sklearn.model_selection import train_test_split\n----&gt; 3 X = df_encoded[features]\n      4 y = df_encoded[target]\n      6 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nNameError: name 'df_encoded' is not defined\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[6], line 5\n      2 from sklearn.metrics import classification_report\n      4 rf = RandomForestClassifier(n_estimators=100, random_state=42)\n----&gt; 5 rf.fit(X_train, y_train)\n      7 y_pred = rf.predict(X_test)\n      8 print(classification_report(y_test, y_pred))\n\nNameError: name 'X_train' is not defined\n\n\n\n\nimport plotly.express as px\nfig = px.bar(\n    x=rf.feature_importances_,\n    y=features,\n    orientation='h',\n    labels={'x': 'Importance', 'y': 'Feature'},\n    title='Feature Importance – ML Role Classification'\n)\n\nfig.update_layout(\n    yaxis=dict(categoryorder='total ascending'),\n    margin=dict(l=100, r=20, t=60, b=20),\n    width=800,\n    height=500,\n    template='plotly_white'\n)\n\nfig.write_html(\n    'figures/rm_model_plot1.html',\n    include_plotlyjs='cdn',\n    full_html=False\n)\n\n\n---------------------------------------------------------------------------\nNotFittedError                            Traceback (most recent call last)\nCell In[7], line 3\n      1 import plotly.express as px\n      2 fig = px.bar(\n----&gt; 3     x=rf.feature_importances_,\n      4     y=features,\n      5     orientation='h',\n      6     labels={'x': 'Importance', 'y': 'Feature'},\n      7     title='Feature Importance – ML Role Classification'\n      8 )\n     10 fig.update_layout(\n     11     yaxis=dict(categoryorder='total ascending'),\n     12     margin=dict(l=100, r=20, t=60, b=20),\n   (...)\n     15     template='plotly_white'\n     16 )\n     18 fig.write_html(\n     19     'figures/rm_model_plot1.html',\n     20     include_plotlyjs='cdn',\n     21     full_html=False\n     22 )\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:671, in BaseForest.feature_importances_(self)\n    650 @property\n    651 def feature_importances_(self):\n    652     \"\"\"\n    653     The impurity-based feature importances.\n    654 \n   (...)\n    669         array of zeros.\n    670     \"\"\"\n--&gt; 671     check_is_fitted(self)\n    673     all_importances = Parallel(n_jobs=self.n_jobs, prefer=\"threads\")(\n    674         delayed(getattr)(tree, \"feature_importances_\")\n    675         for tree in self.estimators_\n    676         if tree.tree_.node_count &gt; 1\n    677     )\n    679     if not all_importances:\n\nFile /opt/hostedtoolcache/Python/3.11.12/x64/lib/python3.11/site-packages/sklearn/utils/validation.py:1757, in check_is_fitted(estimator, attributes, msg, all_or_any)\n   1754     return\n   1756 if not _is_fitted(estimator, attributes, all_or_any):\n-&gt; 1757     raise NotFittedError(msg % {\"name\": type(estimator).__name__})\n\nNotFittedError: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n\n\n\n\n\nThis bar chart displays the feature importance scores from a random forest model predicting whether a job role involves ML/Data Science. The most influential feature by far in the model is the job title (TITLE), which has a significantly higher importance than all other variables. Secondary contributors include industry classification (NAICS2_NAME) and minimum years of experience, where education level and SOC code had relatively low influence on the model’s prediction. This is suggesting that the job title alone carries strong predictive power for identifying ML-related roles.\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Cleaned job descriptions\ndf['BODY_clean'] = df['BODY'].fillna(\"\").str.lower()\n\n# Target\ny = df['REQUIRES_ML']  # this should be a binary 1/0 column\n\n# TF-IDF vectorization\ntfidf = TfidfVectorizer(max_features=5000, stop_words='english')\nX = tfidf.fit_transform(df['BODY_clean'])\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[8], line 6\n      3 from sklearn.feature_extraction.text import TfidfVectorizer\n      5 # Cleaned job descriptions\n----&gt; 6 df['BODY_clean'] = df['BODY'].fillna(\"\").str.lower()\n      8 # Target\n      9 y = df['REQUIRES_ML']  # this should be a binary 1/0 column\n\nNameError: name 'df' is not defined\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(classification_report(y_test, y_pred))\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[9], line 4\n      1 from sklearn.ensemble import RandomForestClassifier\n      2 from sklearn.metrics import classification_report\n----&gt; 4 X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n      6 model = RandomForestClassifier(random_state=42)\n      7 model.fit(X_train, y_train)\n\nNameError: name 'X' is not defined\n\n\n\n\nimport numpy as np\nimportances = model.feature_importances_\ntop_idx = np.argsort(importances)[-20:]\ntop_words = tfidf.get_feature_names_out()[top_idx]\ntop_importances = importances[top_idx]\n\nfig = px.bar(\n    x=top_importances,\n    y=top_words,\n    orientation='h',\n    labels={'x': 'Importance', 'y': 'Word'},\n    title='Top 20 TF-IDF Words for ML Role Classification'\n)\n\nfig.update_layout(\n    yaxis={'categoryorder':'total ascending'},\n    margin=dict(l=120, r=20, t=60, b=20),\n    width=800, height=600, template='plotly_white'\n)\n\nfig.write_html(\n    'figures/rm_model_plot2.html',\n    include_plotlyjs='cdn',\n    full_html=False\n)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[10], line 2\n      1 import numpy as np\n----&gt; 2 importances = model.feature_importances_\n      3 top_idx = np.argsort(importances)[-20:]\n      4 top_words = tfidf.get_feature_names_out()[top_idx]\n\nNameError: name 'model' is not defined\n\n\n\n\n\nThis bar chart shows the top words contributing to the classification of job roles as Machine Learning (ML)related based on job description data. Surprisingly, the most influential words are “attention,” “chain,” and “supply”, which could be an indication of overlap with supply chain roles or reflect noise in the model. More expected terms like “machine,” “learning,” “python,” “AI,” and “analytics” also appear, reinforcing that relevant technical language still plays a role in identifying ML-related positions. The presence of general words like “strong” or “communication” suggests that not all influential terms are strictly technical.\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport numpy as np\nimport plotly.figure_factory as ff\nlabels = [str(lbl) for lbl in model.classes_]\n\ncm = confusion_matrix(y_test, y_pred)\nlabels = [str(c) for c in model.classes_]  \n\nfig = ff.create_annotated_heatmap(\n    z=cm,\n    x=labels,\n    y=labels,\n    colorscale='Blues',\n    showscale=True,\n    annotation_text=cm,\n    hoverinfo='z'\n)\n\nfig.update_layout(\n    title='Confusion Matrix – ML Role Classification',\n    xaxis_title='Predicted Label',\n    yaxis_title='Actual Label',\n    xaxis=dict(tickmode='array', tickvals=list(range(len(labels))), ticktext=labels),\n    yaxis=dict(tickmode='array', tickvals=list(range(len(labels))), ticktext=labels),\n    width=700,\n    height=600,\n    template='plotly_white',\n    margin=dict(l=80, r=20, t=60, b=80)\n)\n\nfig.write_html(\n    \"figures/rm_model_plot3.html\",\n    include_plotlyjs='cdn',\n    full_html=False\n)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[11], line 4\n      2 import numpy as np\n      3 import plotly.figure_factory as ff\n----&gt; 4 labels = [str(lbl) for lbl in model.classes_]\n      6 cm = confusion_matrix(y_test, y_pred)\n      7 labels = [str(c) for c in model.classes_]  \n\nNameError: name 'model' is not defined\n\n\n\n\n\nWe selected a combination of structured and unstructured features to predict whether a job role requires Machine Learning or Data Science. Structured features such as TITLE, SOC_2021_4_NAME, NAICS2_NAME, MIN_EDULEVELS_NAME, and MIN_YEARS_EXPERIENCE were chosen based on domain relevance—these fields reflect the role’s function, industry, required education, and experience level, all of which can signal ML-related requirements. Additionally, we included the job description BODY text, applying TF-IDF vectorization to extract key terms. This allowed the model to learn from nuanced language patterns within postings. Feature importance and performance metrics confirm that both structured metadata and text data contribute meaningfully to classification accuracy."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Next Normal: AI-Driven Analytics in Action",
    "section": "",
    "text": "Welcome to our deep dive into the evolving landscape of Data Science and Business Analytics in the United States. As industries across the nation increasingly rely on data-driven insights, the role of data science and analytics has become paramount in shaping business strategies, optimizing operations, and driving innovation.\nThe rise of artificial intelligence (AI) is reshaping the landscape of data science and business analytics in the United States, creating both opportunities and challenges for workers and businesses alike. As AI continues to evolve, it has sparked widespread concern over job displacement. According to a recent report from the World Economic Forum, 86% of workers express concerns about AI potentially leading to job losses, with predictions of significant industry shifts occurring within the next two to five years (Samuels (2024)). However, business leaders emphasize that AI is not merely a tool for job replacement—it’s a transformative force that is changing the nature of work itself. For instance, Rakuten’s partnership with OpenAI to create an internal version of ChatGPT is helping employees work more efficiently, focusing on higher-level tasks rather than being displaced by technology (Samuels (2024)).  One key trend in 2024 is the growing demand for AI-related skills across various industries. A recent Gartner report highlights that many organizations are significantly increasing their investments in AI, with companies projected to spend an average of $2.5 million on AI integration in 2024 (Gartner (2024)). This investment is reshaping job descriptions and workforce requirements, as roles now demand proficiency in AI tools. For example, in software development, GitHub Copilot has been shown to increase programmers’ efficiency by 55%, enabling them to focus on complex problem-solving rather than repetitive coding tasks (GitHub (2023)). As a result, professionals who upskill and learn to work alongside AI will have better career prospects in the future.\nThe career outlook for business analytics and data science professionals remains optimistic, as companies increasingly look to combine AI with human decision-making to enhance productivity and innovation. Industry leaders, including Bev White, CEO of Nash Squared, emphasize that AI is not about eliminating jobs, but rather reshaping them to make work more productive and meaningful (White (2024)). Similarly, PepsiCo’s CIO, Nigel Richardson, believes that while some jobs will be replaced, AI will ultimately create more opportunities than it eliminates (Richardson (2024)). This aligns with a McKinsey report that forecasts AI could generate up to $13 trillion in additional global GDP by 2030, creating new job opportunities in data science, business analytics, and other technology-related fields (Company (2023)).\nThis website explores the latest trends, key developments, and future directions in Data Science and Business Analytics in the U.S. We delve into emerging technologies, the growing demand for skilled professionals, and the impact these fields are having on various industries. Our aim is to provide you with valuable insights into how data science is shaping the future of business and the economy.\nJoin us as we explore:"
  },
  {
    "objectID": "index.html#state-of-the-data-industry",
    "href": "index.html#state-of-the-data-industry",
    "title": "The Next Normal: AI-Driven Analytics in Action",
    "section": "State of the Data Industry",
    "text": "State of the Data Industry\nIntroduce the current landscape: market size, hiring growth, enterprise adoption curves. Highlight key statistics on demand for data roles and major verticals investing in analytics."
  },
  {
    "objectID": "index.html#ethics-and-responsible-ai",
    "href": "index.html#ethics-and-responsible-ai",
    "title": "The Next Normal: AI-Driven Analytics in Action",
    "section": "Ethics & Responsible AI",
    "text": "Ethics & Responsible AI\nDiscuss bias mitigation, data privacy regulations (GDPR, CCPA), and best practices for transparent model governance. Show examples of “AI gone wrong” and how to build trust."
  },
  {
    "objectID": "index.html#scaling-data-platforms",
    "href": "index.html#scaling-data-platforms",
    "title": "The Next Normal: AI-Driven Analytics in Action",
    "section": "Scaling Data Platforms",
    "text": "Scaling Data Platforms\nCover the evolution from monolithic warehouses to modern lakehouse architectures, real-time streaming (Kafka, Pulsar), and orchestration tools (Airflow, Prefect). Include deployment patterns and cost considerations."
  },
  {
    "objectID": "index.html#future-tech-and-innovation",
    "href": "index.html#future-tech-and-innovation",
    "title": "The Next Normal: AI-Driven Analytics in Action",
    "section": "Future Tech & Innovation",
    "text": "Future Tech & Innovation\nZoom out to emerging trends: Generative AI, graph analytics, quantum computing potential. Speculate on where analytics will go next and how professionals can prepare.\n\nBack to top ↑"
  },
  {
    "objectID": "skill_gap.html",
    "href": "skill_gap.html",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "Code\nimport pandas as pd\ndf = pd.read_parquet(\"data/eda.parquet\")"
  },
  {
    "objectID": "skill_gap.html#group-11-skill",
    "href": "skill_gap.html#group-11-skill",
    "title": "Skill Gap Analysis",
    "section": "Group 11 Skill",
    "text": "Group 11 Skill\n\n\nCode\nimport pandas as pd\n\nskills_data = {\n    \"Name\": [\"Binderiya\", \"Pranjul\", \"Pratham\", \"Panyang\"],\n    \"Python\": [4, 4, 5, 3],\n    \"SQL\": [4, 4, 5, 4],\n    \"Machine Learning\": [2, 3, 2, 2],\n    \"PySpark\": [3, 3, 3, 3],\n    \"Excel\": [4, 5, 5, 4],\n    \"Data Visualization\": [5, 5, 3, 3],\n    \"Power Bi/ Tableau\": [4, 5, 3, 4],\n    \"Version Control Git\": [4, 4, 3, 3],\n    \"ETL/Data pipeline\": [3, 2, 1, 2],\n    \"Communication\": [4, 4, 5, 3],\n    \"Project Management\": [5, 5, 5, 3],\n    \"Cloud Computing\": [4, 4, 2, 2]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nPySpark\nExcel\nData Visualization\nPower Bi/ Tableau\nVersion Control Git\nETL/Data pipeline\nCommunication\nProject Management\nCloud Computing\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinderiya\n4\n4\n2\n3\n4\n5\n4\n4\n3\n4\n5\n4\n\n\nPranjul\n4\n4\n3\n3\n5\n5\n5\n4\n2\n4\n5\n4\n\n\nPratham\n5\n5\n2\n3\n5\n3\n3\n3\n1\n5\n5\n2\n\n\nPanyang\n3\n4\n2\n3\n4\n3\n4\n3\n2\n3\n3\n2\n\n\n\n\n\n\n\n\n\nCode\nimport plotly.express as px\n\nfig = px.imshow(\n    df_skills,\n    text_auto=True,                \n    color_continuous_scale=\"YlGnBu\",\n    aspect=\"auto\"                 \n)\n\nfig.update_layout(\n    title=\"Team Skill Levels Heatmap\",\n    xaxis_title=\"Skills\",\n    yaxis_title=\"Team Members\",\n    width=700,\n    height=400,\n    margin=dict(l=50, r=20, t=50, b=50)\n)\n\nfig.write_html(\n    \"figures/skill_gap_plot1.html\",\n    include_plotlyjs=\"cdn\",\n    full_html=False\n)\n\n\n\n\n\n\nCode\nimport plotly.graph_objects as go\nfrom IPython.display import IFrame\nfig = go.Figure()\n\nfor name in df_skills.index:\n    values = df_skills.loc[name].tolist()\n    values += values[:1]  # close the loop\n    fig.add_trace(go.Scatterpolar(\n        r=values,\n        theta=df_skills.columns.tolist() + [df_skills.columns[0]],\n        fill='toself',\n        name=name\n    ))\n\nfig.update_layout(\n    polar=dict(radialaxis=dict(visible=True, range=[0, 5])),\n    showlegend=True,\n    title='Team Skills Radar Chart'\n)\n\nfig.write_html(\n    \"figures/skill_gap_plot2.html\",\n    include_plotlyjs=\"cdn\",\n    full_html=False\n)\n\n\n\n\n\nInteractive Radar Chart\nFrom this radar chart visualization we can see that our team has a lot of room for improvement for skills like PySpark and Machine Learning. Also we can see that not a lot of our team mates are confident in their skills in Cloud Computing and ETL."
  },
  {
    "objectID": "skill_gap.html#top-skills",
    "href": "skill_gap.html#top-skills",
    "title": "Skill Gap Analysis",
    "section": "Top Skills",
    "text": "Top Skills\n\n\nCode\nkeywords = ['Data Analyst', 'Business Analyst', 'Data Engineering', 'Deep Learning',\n            'Data Science', 'Data Analysis','Data Analytics',  'Market Research Analyst' \n            'LLM', 'Language Model', 'NLP', 'Natural Language Processing',\n            'Computer Vision', 'Business Intelligence Analyst', 'Quantitative Analyst', 'Operations Analyst']\n\nmatch = lambda col: df[col].str.contains('|'.join(keywords), case=False, na=False)\n\ndf['DATA_ANALYST_JOB'] = match('TITLE_NAME') \\\n             | match('SKILLS_NAME') \\\n             | match('SPECIALIZED_SKILLS_NAME') \ndf['DATA_ANALYST_JOB'].value_counts()\n\n\nDATA_ANALYST_JOB\nFalse    37043\nTrue     32155\nName: count, dtype: int64\n\n\n\n\nCode\nimport ast\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n# Safely apply literal_eval only to non-null values\ndf['SKILLS'] = df['SKILLS_NAME'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n\n\ndata_skills = df[df['DATA_ANALYST_JOB']]['SKILLS'].explode().value_counts().reset_index()\ndata_skills.columns = ['Skill', 'Count']\n\nfig = px.bar(data_skills, x='Skill', y='Count',\n             title=\"Top Skills\",\n             labels={'Skill': 'Skill Name', 'Count': 'Frequency'},\n             color='Skill')\ndf_skills.index = df_skills.index.str.strip()\n\n\n\n\nCode\nfrom collections import defaultdict\n\n# Lowercase everything\nteam_skills = [s.lower().strip() for s in df_skills.columns]\njob_demand_raw = data_skills.copy()\njob_demand_raw['Skill'] = job_demand_raw['Skill'].str.lower().str.strip()\n\n# New dict to map cleaned team skill to total count from job postings\nskill_demand_map = defaultdict(int)\n\nfor _, row in job_demand_raw.iterrows():\n    skill_in_posting = row['Skill']\n    count = row['Count']\n    for team_skill in team_skills:\n        if team_skill in skill_in_posting:\n            skill_demand_map[team_skill] += count\n\n\n\n\nCode\nteam_skills = [s.strip().lower() for s in df_skills.columns]\nprint(\"Team skills:\", team_skills)\nprint(job_demand_raw['Skill'].head(10).tolist())\nfor skill_text in job_demand_raw['Skill'].head(10):\n    for team_skill in team_skills:\n        if team_skill in skill_text:\n            print(f\" '{team_skill}' found in: '{skill_text}'\")\n\n\nTeam skills: ['python', 'sql', 'machine learning', 'pyspark', 'excel', 'data visualization', 'power bi/ tableau', 'version control git', 'etl/data pipeline', 'communication', 'project management', 'cloud computing']\n['data analysis', 'sql (programming language)', 'communication', 'management', 'python (programming language)', 'tableau (business intelligence software)', 'dashboard', 'computer science', 'problem solving', 'power bi']\n 'sql' found in: 'sql (programming language)'\n 'communication' found in: 'communication'\n 'python' found in: 'python (programming language)'\n\n\n\n\nCode\nfor _, row in job_demand_raw.iterrows():\n    skill_text = row['Skill']\n    count = row['Count']\n    for team_skill in team_skills:\n        if team_skill in skill_text:  # no regex, just substring\n            skill_demand_map[team_skill] += count\n\njob_demand = pd.Series(skill_demand_map)\nprint(job_demand)\n\n\nsql                   47368\ncommunication         47728\npython                21852\nexcel                 18682\ndata visualization    14568\nproject management    14568\nmachine learning       8386\ncloud computing        2390\npyspark                1008\ndtype: int64\n\n\n\n\nCode\njob_demand = pd.Series(skill_demand_map)\njob_demand.name = \"Count\"\nteam_avg = df_skills.mean()\nteam_avg.index = team_avg.index.str.strip().str.lower() \n# Now match only overlapping skills\ncommon_skills = job_demand.index.intersection(team_avg.index)\nteam_avg = team_avg[common_skills]\njob_demand = job_demand[common_skills]\n\n# Normalize job demand\njob_demand_normalized = 5 * (job_demand / job_demand.max())\njob_demand_normalized.name = \"Job Demand (Normalized)\"\n\n# Combine\ncomparison_df = pd.concat([team_avg, job_demand_normalized], axis=1)\ncomparison_df.columns = [\"Team Average Skill\", \"Job Demand (Normalized)\"]\ncomparison_df[\"Skill Gap\"] = comparison_df[\"Job Demand (Normalized)\"] - comparison_df[\"Team Average Skill\"]\ncomparison_df.sort_values(\"Skill Gap\", ascending=False, inplace=True)\n\ncomparison_df\n\n\n\n\n\n\n\n\n\nTeam Average Skill\nJob Demand (Normalized)\nSkill Gap\n\n\n\n\ncommunication\n4.00\n5.000000\n1.000000\n\n\nsql\n4.25\n4.962286\n0.712286\n\n\nmachine learning\n2.25\n0.878520\n-1.371480\n\n\npython\n4.00\n2.289222\n-1.710778\n\n\ndata visualization\n4.00\n1.526148\n-2.473852\n\n\nexcel\n4.50\n1.957132\n-2.542868\n\n\ncloud computing\n3.00\n0.250377\n-2.749623\n\n\npyspark\n3.00\n0.105598\n-2.894402\n\n\nproject management\n4.50\n1.526148\n-2.973852\n\n\n\n\n\n\n\n\n\nCode\ncomparison_df = comparison_df.reset_index().rename(columns={\"index\": \"Skill\"})\n\n\n\n\nCode\nimport plotly.express as px\n\nfig = px.bar(\n    comparison_df,\n    x='Skill',\n    y='Skill Gap',\n    color='Skill Gap',\n    color_continuous_scale='RdBu_r',\n    title='Skill Gaps: Job Market Expectations vs. Team Capability',\n    labels={'Skill Gap': 'Gap (Job Demand - Team Skill)', 'Skill': 'Skill'},\n)\n\nfig.add_hline(y=0, line_dash='dash')\nfig.update_layout(\n    xaxis_tickangle=-45,\n    yaxis_title='Gap (Positive = Market expects more)',\n    font=dict(size=13),\n    height=500,\n    plot_bgcolor='white',\n)\nfig.write_html(\n    \"figures/skill_gap_plot3.html\",\n    include_plotlyjs=\"cdn\",\n    full_html=False\n)\n\n\n\n\nThis bar chart compares our team’s average proficiency in key data-related skills against job market expectations. Skills with positive values (like communication and SQL) indicate areas where market demand exceeds our current capabilities. On the other hand, negative values highlight areas where the team is ahead or closely aligned with market needs. Notably, skills like Python, cloud computing, and project management show the largest gaps, suggesting priority areas for upskilling."
  },
  {
    "objectID": "analytics_model.html",
    "href": "analytics_model.html",
    "title": "Analytics Model",
    "section": "",
    "text": "Code\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import adjusted_rand_score\neda = pd.read_parquet(\"data/eda.parquet\")\n\n\n\n\nCode\nfeatures = eda[['SALARY', 'MAX_YEARS_EXPERIENCE', 'MIN_YEARS_EXPERIENCE']].copy()\n\nfor col in ['MAX_YEARS_EXPERIENCE', 'MIN_YEARS_EXPERIENCE', 'SALARY']:\n    features[col] = pd.to_numeric(features[col], errors='coerce')\n\nfeatures = features.dropna()\n\nscaler = StandardScaler()\nX = scaler.fit_transform(features)\n\nkmeans = KMeans(n_clusters=4, random_state=688)\neda.loc[features.index, 'Cluster'] = kmeans.fit_predict(X)\n\ntrue_labels = eda.loc[features.index, 'SOC_2021_4_NAME']\ntrue_labels_encoded = LabelEncoder().fit_transform(true_labels)\n\nari = adjusted_rand_score(true_labels_encoded, eda.loc[features.index, 'Cluster'])\n\n\n\n\nCode\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom IPython.display import HTML\n\n# 1) Build the DataFrame\ndf_plot = features.copy()\ndf_plot['Cluster'] = eda.loc[features.index, 'Cluster']\n\n# 2) Compute centroids in original units\ncentroids = kmeans.cluster_centers_\ncentroids_x = centroids[:, 0] * X.std(axis=0)[0] + X.mean(axis=0)[0]\ncentroids_y = centroids[:, 1] * X.std(axis=0)[1] + X.mean(axis=0)[1]\n\n# 3) Create an interactive Plotly Figure\nfig = px.scatter(\n    df_plot,\n    x='SALARY',\n    y='MAX_YEARS_EXPERIENCE',\n    color='Cluster',\n    title=\"KMeans Clustering by Salary and Max Years Experience\",\n    labels={\n        'SALARY': 'Salary',\n        'MAX_YEARS_EXPERIENCE': 'Max Years Experience',\n        'Cluster': 'Cluster'\n    },\n    width=800,\n    height=500,\n)\n\n# 4) Add centroid traces\nfig.add_trace(\n    go.Scatter(\n        x=centroids_x,\n        y=centroids_y,\n        mode='markers',\n        marker=dict(symbol='x', size=18, color='black', line=dict(width=2, color='white')),\n        name='Centroids'\n    )\n)\n\nfig.write_html(\n    \"figures/analytics_plot1.html\",\n    include_plotlyjs=\"cdn\",\n    full_html=True\n)\nfig\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\nHere we have 4 cluster groups. Group 0, which represent as green have lower salary, mostly under 150k, and max years experience in 2-5 years, it is likely Likely junior to mid-level employees with moderate pay. Group 1 with orange, has medium to high salary, wide range from $100k–$500k and with narrow range ~3 years, they are suggests specialized or high-paying roles with short experience — possibly fast-track promotions or high-demand fields. cluster 2 are low salary and experience from 0-4 years, they are clearly entry level employee. cluster 3 has medium salary, mostly under 200k with higher experiences, like 6-13 eyars. They probably are senior professionals with more experience but not the highest salaries.\n\n\nCode\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport plotly.graph_objects as go\n\n# Prepare features & target\nfeatures = eda[['MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE']].apply(pd.to_numeric, errors='coerce')\nfeatures = features.dropna()\nX = features\ny = eda.loc[X.index, 'SALARY']\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=688)\n\n# Fit model & predict\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n# Metrics (optional, but handy)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nprint(f\"MSE: {mse:.2f}, R²: {r2:.3f}\")\n\n# Define min/max for the identity line\nmin_val = y_test.min()\nmax_val = y_test.max()\n\n\nMSE: 798670510.44, R²: 0.089\n\n\n\n\nCode\nfig = go.Figure([\n    go.Scatter(\n        x=y_test,\n        y=y_pred,\n        mode='markers',\n        marker=dict(color='skyblue', opacity=0.6),\n        name='Predicted vs Actual'\n    ),\n    go.Scatter(\n        x=[min_val, max_val],\n        y=[min_val, max_val],\n        mode='lines',\n        line=dict(color='red', dash='dash'),\n        name='Ideal Fit'\n    )\n])\n\nfig.update_layout(\n    title='Actual vs Predicted Salary (Multiple Regression)',\n    xaxis_title='Actual Salary',\n    yaxis_title='Predicted Salary',\n    width=800,\n    height=600,\n    template='plotly_white'\n)\n\n\nfig.write_html(\n    'figures/analytics_plot2.html',\n    include_plotlyjs='cdn',\n    full_html=False\n)\nfig\n\n\n                            \n                                            \n\n\n\n\nThis plot shows the Actual vs. Predicted Salary using a multiple linear regression model. The blue dots represent individual predictions, and the red dashed line is the ideal line where predicted = actual. Since most points lie very close to the red line, it means your model predicts salary very accurately, with minimal error and strong linear fit — likely reflected in a high R² score near 1.0."
  }
]