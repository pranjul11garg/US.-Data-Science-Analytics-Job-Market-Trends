[
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "This document outlines the data cleaning process, including: - Handling missing values - Dropping unnecessary columns - Deduplicating records\n\n# columns drop\nimport pandas as pd\nimport gdown\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport gdown\nimport zipfile\nimport os\n\n\nfile_id = \"1VNBTxArDMN2o9fJBDImaON6YUAyJGOU6\" \nzip_file = \"lightcast_job_postings.zip\"  # Name of the downloaded ZIP file\ncsv_file = \"./data/lightcast_job_postings.csv\"  # Path to the CSV file\n\n# Step 1: Download the Dataset\nprint(\"Downloading the dataset...\")\ngdown.download(f\"https://drive.google.com/uc?id={file_id}\", zip_file, quiet=False)\n\n# Step 2: Unzip the File\nprint(\"Extracting files...\")\nwith zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n    zip_ref.extractall(\"./data\")  # Extracts to 'data' directory\n\n# Step 3: Read the CSV File\nprint(\"Reading the CSV file...\")\ndf = pd.read_csv(csv_file)\n\n# Display dataset info\nprint(\"Dataset Loaded Successfully!\")\nprint(df.info())\n\nprint(\"Available columns in dataset:\", df.columns.tolist())\n\nDownloading the dataset...\n\n\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1VNBTxArDMN2o9fJBDImaON6YUAyJGOU6\nFrom (redirected): https://drive.google.com/uc?id=1VNBTxArDMN2o9fJBDImaON6YUAyJGOU6&confirm=t&uuid=0714bfc7-fa7e-4d81-8de4-5baa8d86a178\nTo: /home/runner/work/ad688-employability-sp25A1-group11/ad688-employability-sp25A1-group11/lightcast_job_postings.zip\n  0%|          | 0.00/190M [00:00&lt;?, ?B/s]  0%|          | 524k/190M [00:00&lt;00:36, 5.23MB/s]  4%|▍         | 7.34M/190M [00:00&lt;00:04, 39.7MB/s]  8%|▊         | 14.7M/190M [00:00&lt;00:03, 51.8MB/s] 10%|█         | 19.9M/190M [00:00&lt;00:04, 40.9MB/s] 13%|█▎        | 24.6M/190M [00:00&lt;00:04, 39.9MB/s] 20%|█▉        | 37.7M/190M [00:00&lt;00:02, 65.1MB/s] 26%|██▌       | 48.8M/190M [00:00&lt;00:02, 58.6MB/s] 32%|███▏      | 60.8M/190M [00:01&lt;00:01, 72.9MB/s] 36%|███▋      | 69.2M/190M [00:01&lt;00:01, 69.7MB/s] 41%|████      | 78.1M/190M [00:01&lt;00:01, 74.4MB/s] 48%|████▊     | 90.7M/190M [00:01&lt;00:01, 86.9MB/s] 55%|█████▌    | 105M/190M [00:01&lt;00:00, 101MB/s]   61%|██████    | 116M/190M [00:01&lt;00:00, 98.8MB/s] 67%|██████▋   | 127M/190M [00:01&lt;00:00, 98.5MB/s] 74%|███████▍  | 141M/190M [00:01&lt;00:00, 110MB/s]  82%|████████▏ | 156M/190M [00:01&lt;00:00, 119MB/s] 89%|████████▊ | 168M/190M [00:02&lt;00:00, 107MB/s] 95%|█████████▍| 180M/190M [00:02&lt;00:00, 106MB/s]100%|██████████| 190M/190M [00:02&lt;00:00, 84.8MB/s]\n\n\nExtracting files...\nReading the CSV file...\nDataset Loaded Successfully!\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 72476 entries, 0 to 72475\nColumns: 131 entries, ID to NAICS_2022_6_NAME\ndtypes: bool(2), float64(11), int64(27), object(91)\nmemory usage: 71.5+ MB\nNone\nAvailable columns in dataset: ['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\n\ndf.drop(columns=columns_to_drop, inplace=True)\nprint(\"Dropped unnecessary columns.\")\nprint(df.columns)\n\n# handle missing value\nprint(\"Missing values before cleaning:\")\nprint(df.isnull().sum())\n\nDropped unnecessary columns.\nIndex(['LAST_UPDATED_DATE', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES',\n       'SOURCES', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY',\n       'MODELED_EXPIRED',\n       ...\n       'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3',\n       'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME',\n       'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6',\n       'NAICS_2022_6_NAME'],\n      dtype='object', length=118)\nMissing values before cleaning:\nLAST_UPDATED_DATE        0\nPOSTED                   0\nEXPIRED               7822\nDURATION             27294\nSOURCE_TYPES             0\n                     ...  \nNAICS_2022_4_NAME        0\nNAICS_2022_5             0\nNAICS_2022_5_NAME        0\nNAICS_2022_6             0\nNAICS_2022_6_NAME        0\nLength: 118, dtype: int64\n\n\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\n# Check column names\ndf.columns = df.columns.str.upper().str.strip()  # Normalize column names\nprint(df.columns)  # Debugging step\n\n# Visualize missing data\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Check if \"SALARY\" exists before filling missing values\nif \"SALARY\" in df.columns:\n    df[\"SALARY\"].fillna(df[\"SALARY\"].median(), inplace=True)\nelse:\n    print(\"⚠️ Warning: 'SALARY' column not found in dataframe!\")\n\n# Check if \"INDUSTRY\" exists before filling missing values\nif \"INDUSTRY\" in df.columns:\n    df[\"INDUSTRY\"].fillna(\"Unknown\", inplace=True)\nelse:\n    print(\"⚠️ Warning: 'INDUSTRY' column not found in dataframe!\")\n\nprint(\"✅ Missing value handling complete.\")\n\nIndex(['LAST_UPDATED_DATE', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES',\n       'SOURCES', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY',\n       'MODELED_EXPIRED',\n       ...\n       'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3',\n       'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME',\n       'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6',\n       'NAICS_2022_6_NAME'],\n      dtype='object', length=118)\n\n\n\n\n\n\n\n\n\n⚠️ Warning: 'SALARY' column not found in dataframe!\n⚠️ Warning: 'INDUSTRY' column not found in dataframe!\n✅ Missing value handling complete.\n\n\n# delete duplicates\ndf = df.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"])\nprint(\"Duplicates removed.\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Business_Analytics_Trends",
    "section": "",
    "text": "The rise of AI is creating both fear and opportunity in the job market. According to the article, 86% of workers worry about job losses due to AI, with some predicting major shifts in the next two to five years. However, business leaders argue that AI isn’t just about replacing jobs—it’s about transforming them. For instance, Rakuten has partnered with OpenAI to create an internal version of ChatGPT, allowing employees to work more efficiently rather than losing their jobs. This highlights how AI is changing the workplace, not necessarily eliminating roles entirely[@samuels2024ai].\nA key trend in 2024 is the growing demand for AI-related skills across different industries. The article mentions that many organizations are now investing in AI, with companies expected to spend an average of $2.5 million on AI integration this year. As a result, job descriptions are evolving, requiring workers to adapt. For example, in software development, GitHub Copilot has made programmers 55% more efficient, allowing them to focus on complex problem-solving rather than repetitive coding. This shift means employees who upskill and learn to work alongside AI will have better career prospects.\nThe overall career outlook for business analytics and data science professionals remains positive, as companies look for ways to combine AI with human decision-making. The CEO of Nash Squared, Bev White, emphasizes that AI won’t just take jobs away but will reshape them, making workplaces more productive and allowing professionals to focus on meaningful, strategic tasks. Similarly, PepsiCo’s CIO, Nigel Richardson, believes that while some jobs will be replaced, AI will ultimately create more opportunities than it eliminates. The key takeaway is that success in this AI-driven era will depend on embracing change, reskilling, and staying adaptable rather than resisting technological advancements.\nWe will add more on this later"
  }
]